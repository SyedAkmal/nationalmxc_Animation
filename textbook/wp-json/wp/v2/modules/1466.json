{"id":1466,"date":"2020-08-17T18:00:48","date_gmt":"2020-08-17T17:00:48","guid":{"rendered":"https:\/\/susodigital.com\/textbook\/?post_type=module&#038;p=1466"},"modified":"2020-09-11T15:22:06","modified_gmt":"2020-09-11T14:22:06","slug":"mastering-crawl","status":"publish","type":"module","link":"https:\/\/susodigital.com\/textbook\/module\/technical-seo\/mastering-crawl","title":{"rendered":"Mastering Google\u2019s Crawl"},"featured_media":0,"parent":410,"menu_order":48,"template":"","acf":{"module_quiz":"","module_time":"102","module_difficulty":{"value":"intermediate","label":"Intermediate"},"module_short_description":"<p>A thorough guide on how to make sure that your website is bot-friendly.<\/p>\n","module_long_description":"<p>In this chapter we take a thorough look at how to ensure that your website can be crawled by Google and is bot-friendly.<\/p>\n","video_file":false,"video_url":"","content":"<p>One of the cornerstones and often most overlooked aspects of SEO is site crawlability (and by extension indexability) &#8211; i.e. the art of sculpting your website in a way that Googlebot can crawl and index your web pages correctly.<\/p>\n<p>After all, if Googlebot (and other search engine robots) can\u2019t find your web pages, then they won\u2019t be indexed, and if they aren\u2019t indexed, then your web pages have no chance of ranking.<\/p>\n<p>Essentially, a bot-friendly website drastically improves your chances of search engines discovering your content and making it available to users. Sometimes even the smallest of tweaks can result in large gains in the SERPs. However, a false step can be detrimental to your site\u2019s crawlability as important pages may not be crawled.<\/p>\n<p>Therefore, in this section, we\u2019ll walk you through the best ways in which you can optimise your website\u2019s crawlability and indexability.<\/p>\n<h2>Page Blocking<\/h2>\n<p>We have seen in the <a href=\"https:\/\/susodigital.com\/textbook\/module\/how-google-works\" target=\"_blank\" rel=\"nofollow noopener\">How Google Works<\/a> module, that Google assigns each website with a <a href=\"https:\/\/susodigital.com\/textbook\/module\/how-google-works\/the-crawling-phase\" target=\"_blank\" rel=\"nofollow noopener\">crawl budget<\/a> i.e. the number of URLs that Googlebot can and wants to crawl.<\/p>\n<p>Page blocking helps you to ensure that Google only discovers the most important pages that you want it to crawl, meaning that your precious crawl budget is not wasted.<\/p>\n<p>Let\u2019s see how you can go about blocking particular pages from being crawled\/indexed by Google.<\/p>\n<h3>Robots.txt<\/h3>\n<p>One of the simplest and most common ways to block pages is with the robots.txt file.<\/p>\n<h4>What is a robots.txt file?<\/h4>\n<p>The robots.txt file, which should be stored in the root directory of your domain, instructs which pages or files search engine bots can and cannot access from your site. Originally designed to prevent DDOS attacks (i.e. to avoid search engines from overloading your website with lots of requests), the robots.txt file is not a mechanism from preventing Google from indexing the web page. In order to do this, you need to either protect the page with a password or use noindex directives.<\/p>\n<h4>What Does a robots.txt File Look Like?<\/h4>\n<p>Below is an example of a basic robots.txt file template.<\/p>\n<pre>User-agent: [bot identifier]\r\n[directive 1]\r\n[directive 2]\r\n[directive ...]\r\n\r\nUser-agent: [another bot identifier]\r\n[directive 1]\r\n[directive 2]\r\n[directive ...]\r\n\r\nSitemap: [URL of Sitemap]<\/pre>\n<p>A robots.txt file generally consists of one or more rules where each rule blocks (or allows) a crawler from accessing a specified file or web page. access for a given crawler to a specified file path in that website.<\/p>\n<p>Here\u2019s an example of a simple (but common) robots.txt file:<\/p>\n<pre>User-agent: *\r\nDisallow: \/wp-admin\/\r\nAllow: \/wp-admin\/admin-ajax.php\r\n\r\nSitemap: https:\/\/example.com\/sitemap.xml\r\n\r\n<\/pre>\n<p>Want to find your robots.txt file?<\/p>\n<p>Simply navigate to the following URL in your browser to access your robots.txt: yourdomain.com\/robots.txt.<\/p>\n<p>It will look something like this:<\/p>\n<img loading=\"lazy\" class=\"alignnone size-full wp-image-1470\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-robots.png\" alt=\"\" width=\"513\" height=\"190\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-robots.png 513w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-robots-108x40.png 108w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-robots-216x80.png 216w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-robots-81x30.png 81w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-robots-162x60.png 162w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-robots-65x24.png 65w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-robots-130x48.png 130w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-robots-49x18.png 49w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-robots-97x36.png 97w\" sizes=\"(max-width: 513px) 100vw, 513px\" \/>\n<h4>User-Agents<\/h4>\n<p>This specifies which robots should follow the rules outlined in the robots.txt file. Each search engine has its own user-agent and you can set custom instructions for each of these in your robots.txt file.<\/p>\n<p>Here are some user-agents that are useful for SEO:<\/p>\n<div class=\"list-styles list-styles__circle list-styles__circle--primary-color\"><ul>\n<li>Google: Googlebot<\/li>\n<li>Google Images: Googlebot-Image<\/li>\n<li>Bing: Bingbot<\/li>\n<li>Yahoo: Slurp<\/li>\n<li>Baidu: Baiduspider<\/li>\n<li>Yandex: YandexBot<\/li>\n<\/ul>\n<\/div>\n<p>You can also use the asterisk (*) wildcard to assign directives to all user-agents.<\/p>\n<p>So for example, if you wanted to block all user-agents except for Googlebot and Bingbot, here\u2019s how you would do it:<\/p>\n<pre>User-agent: *\r\nDisallow: \/\r\n\r\nUser-agent: Googlebot\r\nAllow: \/\r\n\r\nUser-agent: Bingbot\r\nAllow: \/<\/pre>\n<h4>Directives<\/h4>\n<p>Directives outline the rules that you want the user-agents that you declared above to follow.<\/p>\n<p>Below are the most common directives that Google currently supports.<\/p>\n<p><u>Disallow<\/u><\/p>\n<p>This directive instructs spiders not to access certain files\/resources on your website. In our simple example from above, we are telling the search engine bots not to crawl the \/wp-admin\/ folders (because this is where a lot of important files are stored for WordPress websites). You can add as many of these directives as you please.<\/p>\n<p><u>Allow<\/u><\/p>\n<p>This directive should be used to allow search engine bots to access a page or subdirectory. In our example, we are telling the spiders that despite being inside the \/wp-admin\/ folder, it is still allowed to crawl the \/admin-ajax.php file. You can add as many of these directives as you please.<\/p>\n<p><u>Sitemap<\/u><\/p>\n<p>This tells the search engine bots where they can find your XML sitemap(s). It\u2019s worth noting that this is one of the most commonly forgotten lines from the robots.txt file. If you\u2019ve already submitted your sitemap(s) through Google Search Console, then including the location on the robots.txt is redundant, though it\u2019s still important to use this directive as it tells other search engines like Bing where to find your sitemap.<\/p>\n<p>You can find a full list of directives for robots.txt files supported by Google <a href=\"https:\/\/developers.google.com\/search\/reference\/robots_txt\" target=\"_blank\" rel=\"nofollow noopener\">here<\/a>.<\/p>\n<h4>How to Create a robots.txt File<\/h4>\n<p>To create a robots.txt file, simple open a blank .txt document (text file) and begin typing directives.<\/p>\n<p>Remember to name your file robots.txt and save it in the root directory of the subdomain to which it applies &#8211; otherwise it will not be found.<\/p>\n<p>You can also use a <a href=\"http:\/\/tools.seobook.com\/robots-txt\/generator\/\" target=\"_blank\" rel=\"nofollow noopener\">robots.txt generator<\/a> to help eliminate any syntax errors which may prove to be catastrophic to your SEO. However, one downside is that there will be limitations to how customisable you can make it.<\/p>\n<p>For more detailed instructions on how to create your robots.txt file, head <a href=\"https:\/\/support.google.com\/webmasters\/answer\/6062596?hl=en&amp;ref_topic=6061961\" target=\"_blank\" rel=\"nofollow noopener\">here<\/a>.<\/p>\n<h4>robots.txt Common Pitfalls and Best Practices<\/h4>\n<p>Here are some of the most common mistakes that we tend to see when it comes to incorrect robots.txt files:<\/p>\n<p>1. Blocking Googlebot &#8211; ensure that your robots.txt does not have any of the following:<\/p>\n<pre>User-agent: Googlebot\r\nDisallow: \/\r\n\r\nUser-agent: *\r\nDisallow: \/<\/pre>\n<p>This may seem trivial, but both of these are telling Googlebot not to access your entire website. To fix this, simply remove them.<\/p>\n<p>2. Each directive should be on a new line &#8211; To avoid potentially confusing search engine bots, ensure that each directive is on its own line.<\/p>\n<p>Good example:<\/p>\n<pre>User-agent: * \r\nDisallow: \/directory-1\/ \r\nAllow: \/directory-2\/<\/pre>\n<p>Bad example:<\/p>\n<pre>User-agent: * Disallow: \/directory-1\/ Allow: \/directory-2\/<\/pre>\n<p>3. Simplify instructions by using wildcards &#8211; wildcards can be used to apply directives to user-agents as well as match URL patterns when declaring these directives. For instance, if you want to prevent search engines from accessing product category pages that have parameters on your website, you could use something like this:<\/p>\n<pre>User-agent: * \r\nDisallow: \/products\/*?<\/pre>\n<p>This would block any pages that have any product pages with \u201c?\u201d within the URL.<\/p>\n<p>4. Use the \u201c$\u201d wildcard to specify the end of a URL &#8211; If you wanted bots not to access PDF files on your website for example, this qualifier is extremely useful. For example:<\/p>\n<pre>User-agent: * \r\nDisallow: \/*.pdf$<\/pre>\n<p>In the above example, search engines are blocked from accessing any pages that end with .pdf. Note that pages like: pdf?id=123 can still be accessed because they don\u2019t end with \u201c.pdf\u201d.<\/p>\n<p>5. Make your robots.txt human-friendly &#8211; although robots.txt files are primarily for robots, it\u2019s important to ensure that they\u2019re also easy to understand for humans. Adding comments helps describe and explain your robots.txt file to developers.Start the line with a hash (#) to create a comment.<\/p>\n<pre># This instructs Google not to crawl the \/wp-admin\/ subdirectory.\r\nUser-agent: *\r\nDisallow: \/wp-admin\/<\/pre>\n<p>6. Test your robots.txt file &#8211; in order to ensure that there aren\u2019t any issues with your robots.txt file, use <a href=\"https:\/\/support.google.com\/webmasters\/answer\/6062598?hl=en&amp;ref_topic=6061961\" target=\"_blank\" rel=\"nofollow noopener\">Google\u2019s built-in tester<\/a>. This allows you to submit URLs to the tool and see whether it would be blocked\/allowed for Googlebot to access.<\/p>\n<h3 id=\"MR\">Meta Robots<\/h3>\n<h4>What are Meta Robots?<\/h4>\n<p>An extension of the robots directives, the meta robots tags (sometimes referred to as just meta tags) are HTML snippets that can be used to specify your crawl preferences. Meta directives instruct crawlers on how to crawl and index information they find on a specific web page.<\/p>\n<p>The meta robots tags should be placed into the &lt;head&gt; section of a web page.<\/p>\n<h4>Why Are Meta Robots Tags Important For SEO?<\/h4>\n<p>Meta robots tags help prevent web pages from showing up in the SERPs, for example:<\/p>\n<div class=\"list-styles list-styles__circle list-styles__circle--primary-color\"><ul>\n<li>Pages with think content that add little to no value to the user<\/li>\n<li>Pages that are in your development\/staging environment.<\/li>\n<li>Administrative pages such as login pages, thank you pages etc.<\/li>\n<li>Search results from your internal search feature<\/li>\n<li>Pages that contain duplicate content<\/li>\n<\/ul>\n<\/div>\n<p>As a result, meta robots tags enable Google (and other search engines) to efficiently crawl and index your pages whilst preserving precious crawl budget.<\/p>\n<h4>Meta Robots Syntax<\/h4>\n<p>Regardless of whether or not you specify a preference, by default all web pages are set to \u201cindex,follow\u201d &#8211; this means that all pages will be crawled and indexed by Google unless told otherwise. Therefore, adding the following tag to your pages will have no effect:<\/p>\n<pre>&lt;meta name=\u201drobots\u201d content=\"index, follow\"&gt;<\/pre>\n<p>However, if you want to stop a page from being crawled (and indexed) by Google (or other search engines), then use the following syntax.<\/p>\n<pre>&lt;meta name=\"robots\" content=\"noindex\"&gt;<\/pre>\n<p>If you wanted to only prevent Googlebot from indexing a page, use:<\/p>\n<pre>&lt;meta name=\"googlebot\" content=\"noindex\"&gt;<\/pre>\n<h4>Meta Robots Parameters<\/h4>\n<p>Regardless of whether or not you specify a preference, by default all web pages are set to \u201cindex,follow\u201d &#8211; this means that all pages will be crawled and indexed by Google unless told otherwise. Therefore, adding the following tag to your pages will have no effect:<\/p>\n<pre>&lt;meta name=\u201drobots\u201d content=\"index, follow\"&gt;<\/pre>\n<p>However, if you want to stop a page from being crawled (and indexed) by Google (or other search engines), then use the following syntax.<\/p>\n<pre>&lt;meta name=\"robots\" content=\"noindex\"&gt;<\/pre>\n<p>If you wanted to only prevent Googlebot from indexing a page, use:<\/p>\n<pre>&lt;meta name=\"googlebot\" content=\"noindex\"&gt;<\/pre>\n<h4>Meta Robots Parameters<\/h4>\n<p>Below are the parameters that you can use in your meta robots tag.<\/p>\n<div class=\"list-styles list-styles__circle list-styles__circle--primary-color\"><ul>\n<li>index: this instructs the bots to index the page so that they appear in the search results.<\/li>\n<li>noindex: this instructs the bots not to index the page and prevents it from appearing in the search results.<\/li>\n<li>follow: this instructs the bots to crawl the links on the page, and that you also vouch for them<\/li>\n<li>nofollow: this instructs the bots not to crawl the links on the page but note that this does not prevent those linked pages from being indexed, especially if they have other links pointing to them.<\/li>\n<\/ul>\n<\/div>\n<p>These parameters can be combined in the following ways:<\/p>\n<pre>&lt;meta name=\u201drobots\u201d content=\"noindex, nofollow\"&gt;<\/pre>\n<p>&#8211; tells Googlebot not to index the page and not to follow the links on this page.<\/p>\n<pre>&lt;meta name=\u201drobots\u201d content=\"index, follow\"&gt;<\/pre>\n<p>&#8211; tells Googlebot to index the page and to follow the links on this page.<\/p>\n<pre>&lt;meta name=\u201drobots\u201d content=\"noindex, follow\"&gt;<\/pre>\n<p>&#8211; tells Googlebot not to index the page but to follow the links on this page.<\/p>\n<pre>&lt;meta name=\u201drobots\u201d content=\"index, nofollow\"&gt;<\/pre>\n<p>&#8211; tells Googlebot to index the page but not to follow the links on this page.<\/p>\n<p>Other common parameters include:<\/p>\n<div class=\"list-styles list-styles__circle list-styles__circle--primary-color\"><ul>\n<li>none: this behaves the same as combining noindex and nofollow, but should be avoided because other search engines like Bing don\u2019t support this.<\/li>\n<li>all: this is the equivalent to the default value of \u201cindex, follow\u201d.<\/li>\n<li>noimageindex: blocks Google from indexing any of the images that appear on the web page.<\/li>\n<\/ul>\n<\/div>\n<h4>Meta Robots Common Pitfalls and Best Practices<\/h4>\n<p>1. Use commas to separate parameters &#8211; you can combine any number of the parameters that you want by separating them with commas.<\/p>\n<pre>&lt;meta name=\u201drobots\u201d content=\"noindex, nofollow\"&gt;<\/pre>\n<p>2. Conflicting Parameters &#8211; if the parameters conflict, then Google will simply use the most restrictive directive . In the example below, this would be the \u201cnoindex\u201d parameter.<\/p>\n<pre>&lt;meta name=\u201drobots\u201d content=\"noindex, index\"&gt;<\/pre>\n<p>3. Only use meta robots tags if you want to prevent a page from being crawled and indexed &#8211; as mentioned previously, by default all pages are treated as \u201cindex, follow\u201d unless specified otherwise so you only need to add this tag to pages that you do not want Googlebot to crawl.<\/p>\n<p>4. Why is my page not being indexed? &#8211; A common reason why a page may not be indexed by Google is because it may be marked as \u201cnoindex\u201d in the meta robots tag.<\/p>\n<p>5. Noindexed pages being blocked by robots.txt. &#8211; this prevents crawlers from seeing the noindex robots tag which means that the page might still be indexed.<\/p>\n<h3>X-Robots Tag<\/h3>\n<p>The robots meta tag is great for implementing noindex directives on HTML pages, but if you want to block search engines from indexing other resources such as images or PDFs, then the X-Robots tag is a powerful way to do so.<\/p>\n<h4>What is the X-Robots Tag?<\/h4>\n<p>The X-Robots tag can be included as an element of the HTTP header response for a particular URL to control the indexing of the page as a whole, as well as specific elements of the page like images and\/or PDFs.<\/p>\n<p>Here\u2019s an example of what it could look like:<\/p>\n<img loading=\"lazy\" class=\"alignnone size-full wp-image-1472\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-x-robots-tag.png\" alt=\"\" width=\"288\" height=\"183\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-x-robots-tag.png 288w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-x-robots-tag-63x40.png 63w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-x-robots-tag-126x80.png 126w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-x-robots-tag-47x30.png 47w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-x-robots-tag-94x60.png 94w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-x-robots-tag-38x24.png 38w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-x-robots-tag-76x48.png 76w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-x-robots-tag-28x18.png 28w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-x-robots-tag-57x36.png 57w\" sizes=\"(max-width: 288px) 100vw, 288px\" \/>\n<p>Note that the same directives for meta robots tags can be used for the x-robots-tag.<\/p>\n<h4>How to Use the X-Robots Tag<\/h4>\n<p>In order to use the X-Robots tag, you will need access to either your site\u2019s header .php, .htaccess, or server access file.<\/p>\n<p>Here\u2019s an example of the code that you may use to block off a page with PHP:<\/p>\n<pre>header(\u201cX-Robots-Tag: noindex\u201d, true);<\/pre>\n<p>This method is recommended for blocking specific <u>pages<\/u>.<\/p>\n<p>Here\u2019s an example of the code that you may use for blocking off .doc and .pdf files from the SERPs without having to specify every PDF in your robots.txt file via your .htaccess (or httpd.conf file). This example is for websites that use Apache, the most widely used server-type.<\/p>\n<pre>&lt;FilesMatch \u201c.(doc|pdf)$\u201d&gt;\r\n\r\nHeader set X-Robots-Tag \u201cnoindex, noarchive, nosnippet\u201d\r\n\r\n&lt;\/FilesMatch&gt;<\/pre>\n<p>This method is recommended for blocking specific <u>file types<\/u>.<\/p>\n<h4>When Should You Use the X-Robots-Tag?<\/h4>\n<p>Although meta robots tags are simple to add (it\u2019s just about adding a simple HTML snippet afterall), it isn\u2019t always the best option.<\/p>\n<p>Here are a few cases for why you might employ the x-robots-tag instead of the meta robots tag:<\/p>\n<p>1. Non-HTML files &#8211; Using the X-Robots tag is the only way to control the indexation of non-HTML content like flash, videos, images and PDFs.<\/p>\n<p>2. Blocking indexation of a particular subdomain or subdirectory at once &#8211; bulk editing the meta robots tag for each page on a subdomain or subdirectory is a laborious task and is much easier to do with the x-robots-tag. This is because the x-robots-tag allows for the use of regular expressions, which enables a higher level of flexibility as you can match HTTP header modifications to URLs and\/or file names.<\/p>\n<h2>XML Sitemaps<\/h2>\n<p>You wouldn\u2019t explore a new place without a map (or Google maps), right?<\/p>\n<p>Well, just like that, it can sometimes be difficult for Google to find all of the pages (that you want to be discovered) on your website without the use of a sitemap.<\/p>\n<p>An XML sitemap to be precise.<\/p>\n<h3>What is an XML Sitemap?<\/h3>\n<p>An XML sitemap (or just sitemap) is an XML file which maps out the most important content on your website. Search engines like Google use this file to crawl your website so it\u2019s recommended that you include any page or file that you want to be found by their crawlers within your sitemap.<\/p>\n<p>Here\u2019s the XML sitemap for SUSO Digital.<\/p>\n<img loading=\"lazy\" class=\"alignnone size-full wp-image-1473\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-sitemap.png\" alt=\"\" width=\"1284\" height=\"521\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-sitemap.png 1284w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-sitemap-99x40.png 99w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-sitemap-197x80.png 197w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-sitemap-74x30.png 74w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-sitemap-148x60.png 148w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-sitemap-59x24.png 59w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-sitemap-118x48.png 118w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-sitemap-44x18.png 44w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-sitemap-89x36.png 89w\" sizes=\"(max-width: 1284px) 100vw, 1284px\" \/>\n<p>As you can see, apart from detailing which resources we\u2019d like Googlebot to discover and crawl, the sitemap also provides useful information about the files such as the last updated date of a web page. When this date changes, Google knows that new content is available and aims to crawl and index it.<\/p>\n<p>You can also detail how often web pages have been changed as well as if there are any alternate versions of the page i.e. if your pages are in different languages.<\/p>\n<p>It\u2019s important to note that XML sitemaps can\u2019t be larger than 50MB in size and that you can list up to, but no more than 50,000 URLs.<\/p>\n<p>If you have a very large website, you will need to create more than one sitemap.<\/p>\n<h4>Types of Sitemaps<\/h4>\n<p>Apart from the general XML sitemap which we described above, there are three other types of sitemaps that you can upload to Google:<\/p>\n<p><u>Video Sitemap<\/u><\/p>\n<p>This sitemap is designed to specifically help Google understand the video content that is hosted on your web pages. Here you can add details about the video running time, category, and age-appropriateness rating for each video entry.<\/p>\n<p>Here\u2019s an example of what a Video sitemap looks like:<\/p>\n<img loading=\"lazy\" class=\"alignnone size-full wp-image-1474\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-sitemap-example.png\" alt=\"\" width=\"864\" height=\"726\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-sitemap-example.png 864w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-sitemap-example-48x40.png 48w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-sitemap-example-95x80.png 95w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-sitemap-example-36x30.png 36w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-sitemap-example-71x60.png 71w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-sitemap-example-29x24.png 29w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-sitemap-example-57x48.png 57w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-sitemap-example-21x18.png 21w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-sitemap-example-43x36.png 43w\" sizes=\"(max-width: 864px) 100vw, 864px\" \/>\n<p>&nbsp;<\/p>\n<p>You can find Google\u2019s guidelines on how to create and upload a video sitemap <a href=\"https:\/\/support.google.com\/webmasters\/answer\/80471\" target=\"_blank\" rel=\"nofollow noopener\">here<\/a>.<\/p>\n<p><u>Google News Sitemap<\/u><\/p>\n<p>This sitemap is designed to help Google find and understand articles on websites for Google News. Google News crawls these sitemaps as often as it crawls the rest of your site which means that you can add new articles to this sitemap as they\u2019re published.<\/p>\n<p>Here\u2019s an example of what a Google News sitemap looks like:<\/p>\n<img loading=\"lazy\" class=\"alignnone size-full wp-image-1475\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-news-sitemap-example.png\" alt=\"\" width=\"700\" height=\"381\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-news-sitemap-example.png 700w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-news-sitemap-example-73x40.png 73w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-news-sitemap-example-147x80.png 147w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-news-sitemap-example-55x30.png 55w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-news-sitemap-example-110x60.png 110w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-news-sitemap-example-44x24.png 44w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-news-sitemap-example-88x48.png 88w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-news-sitemap-example-33x18.png 33w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-news-sitemap-example-66x36.png 66w\" sizes=\"(max-width: 700px) 100vw, 700px\" \/>\n<p>You can find Google\u2019s guidelines on how to create and upload a Google News sitemap <a href=\"https:\/\/support.google.com\/webmasters\/answer\/156184\" target=\"_blank\" rel=\"nofollow noopener\">here<\/a>.<\/p>\n<p><u>Image Sitemap<\/u><\/p>\n<p>The image sitemap helps Google find all of the images that you have hosted on your website. On top of this, you can provide additional information about the images such as the subject matter type and licence for each image entry.<\/p>\n<p>Here\u2019s an example of what an Image sitemap looks like:<\/p>\n<img loading=\"lazy\" class=\"alignnone size-full wp-image-1476\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-image-sitemap-example.png\" alt=\"\" width=\"699\" height=\"327\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-image-sitemap-example.png 699w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-image-sitemap-example-86x40.png 86w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-image-sitemap-example-171x80.png 171w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-image-sitemap-example-64x30.png 64w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-image-sitemap-example-128x60.png 128w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-image-sitemap-example-51x24.png 51w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-image-sitemap-example-103x48.png 103w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-image-sitemap-example-38x18.png 38w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-image-sitemap-example-77x36.png 77w\" sizes=\"(max-width: 699px) 100vw, 699px\" \/>\n<p>You can find Google\u2019s guidelines on how to create and upload an image sitemap <a href=\"https:\/\/support.google.com\/webmasters\/answer\/178636\" target=\"_blank\" rel=\"nofollow noopener\">here<\/a>.<\/p>\n<h4>Why Are Sitemaps Important?<\/h4>\n<p>Well, we know sitemaps help Google access the most important (and up to date) content on your website, but they also help in several other ways.<\/p>\n<p>For example, sitemaps become especially important if for example a particular page (that is of value to you), doesn\u2019t have any internal links pointing towards it, and may not be otherwise discovered by the search engine spiders. These are referred to as orphaned pages.<\/p>\n<p>Likewise, if you have a large website (with 500 pages or more), sitemaps prove to be a great way for the search engine (and you) to understand the structure of your website.<\/p>\n<p>It\u2019s worth noting that Google says: <em>\u201cIf your site\u2019s pages are properly linked, our web crawlers can usually discover most of your site.\u201d<\/em>.<\/p>\n<p>This means that not every site will NEED a sitemap, but having one won\u2019t hinder your SEO performance so it doesn\u2019t hurt to use them.<\/p>\n<h3>Breaking Down An XML Sitemap<\/h3>\n<p>XML sitemaps are designed and formatted in a way that\u2019s easy for computers (search engines) to understand. The language used is XML (which stands for Extensible Markup Language).<\/p>\n<p>Here\u2019s an example of a (simple) XML sitemap.<\/p>\n<pre>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\r\n&lt;urlset xmlns=\"http:\/\/www.sitemaps.org\/schemas\/sitemap\/0.9\"&gt;\r\n\t&lt;url&gt;\r\n\t\t&lt;loc&gt;https:\/\/example.com\/&lt;\/loc&gt;\r\n\t\t&lt;lastmod&gt;2020-02-22T11:02:50+04:00&lt;\/lastmod&gt;\r\n\t&lt;\/url&gt;\r\n\t&lt;url&gt;\r\n\t\t&lt;loc&gt;https:\/\/example.com.com\/page-1\/&lt;\/loc&gt;\r\n\t\t&lt;lastmod&gt;2020-03-23T12:56:14+02:00&lt;\/lastmod&gt;\r\n\t&lt;\/url&gt;\r\n&lt;\/urlset&gt;<\/pre>\n<p>Let\u2019s break down the various elements and dive into the details!<\/p>\n<h4>XML Header Declaration<\/h4>\n<pre>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;<\/pre>\n<p>The XML header defines how the contents of the XML file is structured as well as the character encoding. It basically tells the search engine that they\u2019re looking at an XML file, and that the version of XML being used should be 1.0 with the encoding UTF-8.<\/p>\n<p>URL Set Definition<\/p>\n<pre>&lt;urlset xmlns=\"http:\/\/www.sitemaps.org\/schemas\/sitemap\/0.9\"&gt;<\/pre>\n<p>The URL set encapsulates all of the URLs that are outlined in the sitemap and informs the search engine crawlers which version of the XML Sitemap standard is being used. The Sitemap 0.90 standard is the most common specification and is supported by Google, Yahoo! And Microsoft.<\/p>\n<p>Note that the URL Set definition should also be closed at the bottom of the sitemap as follows:<\/p>\n<pre>&lt;\/urlset&gt;<\/pre>\n<h4>URL Definition<\/h4>\n<pre>&lt;url&gt;\r\n\t&lt;loc&gt;https:\/\/example.com\/&lt;\/loc&gt;\r\n\t&lt;lastmod&gt;2020-02-22T11:02:50+04:00&lt;\/lastmod&gt;\r\n&lt;\/url&gt;<\/pre>\n<p>This will be the meat of your sitemap(s) &#8211; the important part!<\/p>\n<p>The &lt;url&gt; identifier serves as the parent tag for each of the URLs that you list in your sitemap. Here, you have to specify the location of the URL within &lt;loc&gt; tags.<\/p>\n<p>Note that these URLs <em><u>must<\/u><\/em> be absolute as opposed to relative canonical URLs.<\/p>\n<p>The &lt;loc&gt; tag is compulsory, but there are a few additional optional properties that you may wish to include:<\/p>\n<div class=\"list-styles list-styles__circle list-styles__circle--primary-color\"><ul>\n<li>&lt;lastmod&gt; &#8211; this specifies the date that the file was last modified. Note that the date must be kept in the<a href=\"https:\/\/www.w3.org\/TR\/NOTE-datetime\" target=\"_blank\" rel=\"nofollow noopener\"> W3C Datetime format<\/a> i.e. if a page was updated on 22nd April 2020, the attribute should be: 2020-04-22. Additionally, you may also wish to include the time too, but this is optional. <a href=\"https:\/\/stackoverflow.com\/questions\/31349345\/how-to-properly-format-last-modified-lastmod-time-for-xml-sitemaps?stw=2\" target=\"_blank\" rel=\"nofollow noopener\">Google\u2019s Gary Ilyes<\/a> states that this attribute is mostly ignored because \u201cwebmasters are doing a horrible job keeping it accurate\u201d.<\/li>\n<li>&lt;priority&gt; &#8211; we mentioned that sitemaps allow you to tell search engines which pages are the most important, you can do this by assigning a priority score between 0.0 and 1.0 (where 0.0 is low priority and 1.0 is very high priority) to each URL. This tells the crawlers how important the URL is in relation to others on your site.<\/li>\n<\/ul>\n<\/div>\n<p>We should note that Google describes this score as a \u201cbag of noise\u201d and actually ignores them as stated by Gary Ilyes in the tweet below; so in practice, they aren\u2019t very important for SEO.<\/p>\n<blockquote class=\"twitter-tweet\">\n<p dir=\"ltr\" lang=\"en\">Will sitemap priority settings be guiding in this one, or don&#8217;t they make a difference?<\/p>\n<p>\u2014 Dennis Stopa (@denstopa) <a href=\"https:\/\/twitter.com\/denstopa\/status\/846794546352701441?ref_src=twsrc%5Etfw\">March 28, 2017<\/a><\/p><\/blockquote>\n<p><script async src=\"https:\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"><\/script><\/p>\n<div class=\"list-styles list-styles__circle list-styles__circle--primary-color\"><ul>\n<li>&lt;changefreq&gt; &#8211; this tag specifies how often the contents of the URL is likely to change. The possible values are: always, hourly, daily, weekly, monthly, yearly, never. But again, <a href=\"https:\/\/www.youtube.com\/watch?v=8k362CTpS6c#t=1776\" target=\"_blank\" rel=\"nofollow noopener\">Google states<\/a> that this is no longer as important and \u201cdoesn\u2019t play as much of a role\u201d anymore.<\/li>\n<\/ul>\n<\/div>\n<h3>Creating Your XML Sitemap<\/h3>\n<p>There are several different ways that you can create your XML sitemap. There are lots of brilliant guides on how to create a XML sitemap already, so here, we\u2019ll simply highlight the various methods and provide links to those great guides.<\/p>\n<p><u>Manually<\/u><\/p>\n<p>For small websites with very few web pages you can create your sitemap relatively easily using the format that we outlined above. All you need to do is open up a text editor and start typing away &#8211; just remember to follow the above guidelines and to save your document as an XML file (i.e. with the extension .xml) otherwise Google won\u2019t be able to read it.<\/p>\n<p><u>Automatically Generated Sitemaps<\/u><\/p>\n<p>If you still want to automate the process (because let\u2019s face it, why wouldn\u2019t you?) or your website is simply too large to manually create a sitemap, then the following tools are great<\/p>\n<div class=\"list-styles list-styles__circle list-styles__circle--primary-color\"><ul>\n<li><a href=\"https:\/\/www.screamingfrog.co.uk\/xml-sitemap-generator\/\" target=\"_blank\" rel=\"nofollow noopener\">ScreamingFrog XML Sitemap Generator<\/a> &#8211; you can still get a free version of ScreamingFrog (a fabulous website crawler and log analysis tool we\u2019ve been using for years now)<a href=\"https:\/\/www.screamingfrog.co.uk\/seo-spider\/\" target=\"_blank\" rel=\"nofollow noopener\"> here<\/a>. (SUSO approved)<\/li>\n<li>WordPress &#8211; if your site is in WP, you can use the following plugins to automatically generate your sitemap.<div class=\"list-styles list-styles__circle list-styles__circle--primary-color\"><\/div>\n<ul>\n<li><a href=\"https:\/\/yoast.com\/help\/xml-sitemaps-in-the-wordpress-seo-plugin\/\" target=\"_blank\" rel=\"nofollow noopener\">Yoast WP XML Sitemap Feature<\/a> (SUSO approved)<\/li>\n<li><a href=\"https:\/\/wordpress.org\/plugins\/google-sitemap-generator\/\" target=\"_blank\" rel=\"nofollow noopener\">Google Sitemap Generator Plugin<\/a><\/li>\n<\/ul>\n<p>&nbsp;<\/li>\n<li>Wix \/ Squarespace \/ Shopify &#8211; if your website is in either of these CMS\u2019s, your sitemap will automatically be generated for you &#8211; you can find your sitemap by accessing: yoursite.com\/sitemap.xml<\/li>\n<li><a href=\"https:\/\/www.xml-sitemaps.com\/\" target=\"_blank\" rel=\"nofollow noopener\">XML-Sitemaps.com<\/a> &#8211; simply enter your website\u2019s URL into this site and it\u2019ll generate a sitemap for you!<\/li>\n<\/ul>\n<\/div>\n<p>Our recommended choices would be ScreamingFrog (or for WP sites, the Yoast Plugin). This is because some of the other plugins\/tools include non-canonical URLs, noindexed pages, and redirects which is not good for SEO.<\/p>\n<p>Regardless of which method you pick, it\u2019s vital that you go through the sitemap yourself to ensure that there aren\u2019t any glaringly obvious omissions or additions.<\/p>\n<h4>Submitting Your Sitemap to Google<\/h4>\n<p>Once you\u2019ve created (and checked) your sitemap and have hosted it on your website (at the root folder), the next step is to make it accessible to Google and other search engines, but before you do that, you need to know where your sitemap is!<\/p>\n<p>Your sitemap can be found at: yoursite.com\/sitemap.xml, though this may vary depending on the CMS you\u2019re using.<\/p>\n<p>Now that you\u2019ve got the URL for your sitemap, submitting it to Google couldn\u2019t be easier!<\/p>\n<p>Simply go to <a href=\"https:\/\/www.google.com\/webmasters\/tools\/home?hl=en\" target=\"_blank\" rel=\"nofollow noopener\">Google Search Console<\/a> &gt; Sitemaps &gt; paste\/type in your sitemap location (i.e. \u201csitemap.xml\u201d) &gt; click \u201cSubmit\u201d<\/p>\n<img loading=\"lazy\" class=\"alignnone size-full wp-image-1480\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-GSC-sitemap.png\" alt=\"\" width=\"1014\" height=\"476\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-GSC-sitemap.png 1014w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-GSC-sitemap-85x40.png 85w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-GSC-sitemap-170x80.png 170w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-GSC-sitemap-64x30.png 64w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-GSC-sitemap-128x60.png 128w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-GSC-sitemap-51x24.png 51w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-GSC-sitemap-102x48.png 102w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-GSC-sitemap-38x18.png 38w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-GSC-sitemap-77x36.png 77w\" sizes=\"(max-width: 1014px) 100vw, 1014px\" \/>\n<p>Tip: You should also specify the path to your sitemap in your robots.txt file by using the sitemap directive.<\/p>\n<p>For example:<\/p>\n<pre>Sitemap: http:\/\/www.example.com\/sitemap.xml<\/pre>\n<p>&#8230;and if you have more than one sitemap, simply add multiple lines:<\/p>\n<pre>Sitemap: http:\/\/www.example.com\/sitemap.xml\r\nSitemap: http:\/\/www.example.com\/sitemap-2.xml\r\nSitemap: http:\/\/www.example.com\/sitemap-3.xml<\/pre>\n<h3>XML Sitemaps Best Practices: A Checklist<\/h3>\n<p>Here\u2019s a quick checklist of best practices to ensure your sitemaps are the best they can possibly be:<\/p>\n<p>1. Are all of your pages indexable? &#8211; only pages that are indexable should be listed in your sitemap, this means any URLs that point to redirects or are missing (return 404 errors) should be omitted from the sitemap. Ensure there are no directives blocking search engines from being indexed like meta robots\/x-robots\/canonical tags.<\/p>\n<p>2. Stick to the default location and filename &#8211; to make it as easy as possible for Google to find your sitemap(s), ensure that you stick to the default location (yoursite.com\/sitemap.xml) and that the filename is sitemap.xml.<\/p>\n<p>3. Have you referenced your sitemap in the robots.txt &#8211; Especially if your sitemap doesn\u2019t follow the default URL path or filename, the best way to ensure Google finds it is to reference it in your robots.txt file, but this should be done regardless.<\/p>\n<p>4. Is your sitemap within limits? &#8211; Ensure your sitemap contains no more than 50,000 URLs and that the file is limited to 50MB. If you exceed either of these limitations, you will need to create another sitemap.<\/p>\n<h2 id=\"C\">Canonicals<\/h2>\n<p>Canonical tags have <a href=\"https:\/\/webmasters.googleblog.com\/2009\/02\/specify-your-canonical.html\" target=\"_blank\" rel=\"nofollow noopener\">been an essential part of SEO for over a decade now<\/a>, they were created by Google, Microsoft and Yahoo in 2009 with the aim to provide webmasters with a solution to solving duplicate content issues with ease.<\/p>\n<h3>What is a Canonical Tag?<\/h3>\n<p>A canonical tag is a snippet of HTML code that allows you to tell search engines which page (or URL) represents the master copy for duplicate, near-duplicate or similar web pages. So, if you have multiple pages that contain the same or very similar content, you can specify which of these Google should treat as the main version or most important and thus, should index.<\/p>\n<img loading=\"lazy\" class=\"alignnone size-full wp-image-1481\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-canonical-tag.jpg\" alt=\"\" width=\"1780\" height=\"1371\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-canonical-tag.jpg 1780w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-canonical-tag-1536x1183.jpg 1536w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-canonical-tag-52x40.jpg 52w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-canonical-tag-104x80.jpg 104w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-canonical-tag-39x30.jpg 39w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-canonical-tag-78x60.jpg 78w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-canonical-tag-31x24.jpg 31w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-canonical-tag-62x48.jpg 62w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-canonical-tag-23x18.jpg 23w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-canonical-tag-47x36.jpg 47w\" sizes=\"(max-width: 1780px) 100vw, 1780px\" \/>\n<p>Google will then understand that the duplicated pages refer to the canonicalised version. On top of this, additional URL properties like the PageRank as well as other related signals are transferred over to the canonicalised page too.<\/p>\n<p>The canonical tag is represented by the following HTML syntax:<\/p>\n<pre>rel = \u201ccanonical\u201d<\/pre>\n<p>Here\u2019s what a canonical tag looks like in practice.<\/p>\n<pre>&lt;link rel=\u201ccanonical\u201d href=\u201chttps:\/\/example.com\/hellow-words-page\/\u201d \/&gt;<\/pre>\n<p>Let\u2019s break it down:<\/p>\n<p>1. link rel=\u201ccanonical\u201d &#8211; this snippet of code tells the search engine that we want the link in this tag to be treated as the main (canonical) version.<\/p>\n<p>2. href=\u201chttps:\/\/example.com\/hellow-words-page\/\u201d &#8211; this tells the search engine the location of the canonical version of the page.<\/p>\n<h3>Why are Canonicals Important for SEO?<\/h3>\n<p>The main reason why canonicals are important for SEO, is to solve the issue of duplicate content.<\/p>\n<p>Google wants to provide users with the best experience possible, which means that diversity in the SERPs is important. With that in mind, duplicate content is something that Google (and other search engines) aren\u2019t keen on at all.<\/p>\n<p>This is because when search engines crawl multiple pages with the same or very similar content, it can cause the following SEO problems:<\/p>\n<div class=\"list-styles list-styles__circle list-styles__circle--primary-color\"><ul>\n<li>Google may not be able to identify which version of a page should be indexed and therefore should rank. Picking the wrong URL would hurt your ranking ability considerably.<\/li>\n<li>Google may not be able to identify relevant queries that a page should rank for.<\/li>\n<li>Google may be unsure as to whether the link authority should be split between the different versions of the page, or just one of the pages.<\/li>\n<li>Having multiple pages wastes crawl budget which may prevent Google from crawling other important pages that actually contain unique content. Canonical pages are crawled more frequently whereas duplicates are crawled less frequently &#8211; so adding a canonical tag will reduce the crawling load on your website.<\/li>\n<\/ul>\n<\/div>\n<p>Using canonical tags will solve all these problems because it puts you in control of any duplicate content that may be present on your site &#8211; whether intentional or not.<\/p>\n<h4>What If You Don\u2019t Specify A Canonical?<\/h4>\n<p>If you have lots of duplicate content and fail to specify a canonical URL, <a href=\"https:\/\/support.google.com\/webmasters\/answer\/139066?hl=en\" target=\"_blank\" rel=\"nofollow noopener\">Google will decide for you<\/a>:<\/p>\n<p><em>\u201cIf you don&#8217;t explicitly tell Google which URL is canonical, Google will make the choice for you, or might consider them both of equal weight, which might lead to unwanted behavior\u201d<\/em><\/p>\n<p>During the indexing process, Googlebot tries to determine the primary content of each web page. But if the crawler finds multiple pages with the same content, it chooses the page that it feels is the most complete and automatically treats it as the canonical.<\/p>\n<p><u>How Does Google Choose the Canonical Page?<\/u><\/p>\n<p>Below are a handful of factors that Google takes into consideration when deciding which page should be treated as the canonical:<\/p>\n<div class=\"list-styles list-styles__circle list-styles__circle--primary-color\"><ul>\n<li>Whether the page is served via HTTP or HTTPS<\/li>\n<li>The quality of the page<\/li>\n<li>Whether the page is listed in a sitemap<\/li>\n<li>Whether the canonical tag is present<\/li>\n<\/ul>\n<\/div>\n<p>Google explains how the above techniques can be used to show Google your preferred page, but that Google still \u201cmay choose a different page as canonical as you\u201d. This is because the above techniques are hints as opposed to strict directives.<\/p>\n<h4>Do I Have Duplicate Content?<\/h4>\n<p>Intentionally? Probably not.<\/p>\n<p>Unintentionally? Maybe.<\/p>\n<p>It\u2019s very unlikely that you\u2019ve been actively publishing the same content on multiple pages, but it\u2019s important to remember that search engines crawl URLs, not web pages.<\/p>\n<p>Let\u2019s look an example of how search crawlers may discover your homepage:<\/p>\n<div class=\"list-styles list-styles__circle list-styles__circle--primary-color\"><ul>\n<li>http:\/\/www.example.com<\/li>\n<li>http:\/\/example.com<\/li>\n<li>https:\/\/www.example.com<\/li>\n<li>https:\/\/example.com<\/li>\n<li>http:\/\/example.com\/index.php<\/li>\n<li>http:\/\/example.com\/index.php?<\/li>\n<\/ul>\n<\/div>\n<p>\u2026 and so on.<\/p>\n<p>Likewise, the URLs&#8230;<\/p>\n<div class=\"list-styles list-styles__circle list-styles__circle--primary-color\"><ul>\n<li>example.com\/product<\/li>\n<li>example.com\/product?price=asc<\/li>\n<\/ul>\n<\/div>\n<p>\u2026 are treated as unique URLs despite the fact that the web page (and content) is the same or very similar.<\/p>\n<p>These kinds of URLs are called <dfn title=\"parameterised URLs are URLs that are dynamically generated by content management systems and\/or dynamic, code-driven websites.\">parameterised URLs<\/dfn> and are extremely common on eCommerce websites that have faceted or filtered navigation (i.e. filtering products by size, colour, availability, most popular, price etc).<\/p>\n<p>For example, Flannels are an online clothing store.<\/p>\n<p>Here\u2019s the URL for their category page for men\u2019s shirts: <a href=\"https:\/\/www.flannels.com\/men\/clothing\/shirts\" target=\"_blank\" rel=\"nofollow noopener\">https:\/\/www.flannels.com\/men\/clothing\/shirts<\/a><\/p>\n<p>Now, let\u2019s see how the URL changes if we filter for only green shirts:<\/p>\n<p><a href=\"https:\/\/www.flannels.com\/men\/clothing\/shirts#dcp=1&amp;dppp=100&amp;OrderBy=rank&amp;Filter=ACOL%5EGreen\" target=\"_blank\" rel=\"nofollow noopener\">https:\/\/www.flannels.com\/men\/clothing\/shirts#dcp=1&amp;dppp=100&amp;OrderBy=rank&amp;Filter=ACOL%5EGreen<\/a><\/p>\n<p>And how about green shirts that are only available in size medium?<\/p>\n<p><a href=\"https:\/\/www.flannels.com\/men\/clothing\/shirts#dcp=1&amp;dppp=100&amp;OrderBy=rank&amp;Filter=ACOL%5EGreen%7CACSIZE%5EM\" target=\"_blank\" rel=\"nofollow noopener\">https:\/\/www.flannels.com\/men\/clothing\/shirts#dcp=1&amp;dppp=100&amp;OrderBy=rank&amp;Filter=ACOL%5EGreen%7CACSIZE%5EM<\/a><\/p>\n<p>If we then also filter for a price range of \u00a350-\u00a3100, yet another parameter is added to the URL:<\/p>\n<p><a href=\"https:\/\/www.flannels.com\/men\/clothing\/shirts#dcp=1&amp;dppp=100&amp;OrderBy=rank&amp;Filter=ACOL%5EGreen%7CACSIZE%5EM%7CAPRI%5E%C2%A350%20to%20%C2%A3100\" target=\"_blank\" rel=\"nofollow noopener\">https:\/\/www.flannels.com\/men\/clothing\/shirts#dcp=1&amp;dppp=100&amp;OrderBy=rank&amp;Filter=ACOL%5EGreen%7CACSIZE%5EM%7CAPRI%5E%C2%A350%20to%20%C2%A3100<\/a><\/p>\n<p>As you can see, each of these pages contain very similar content, but Google treats them as individual pages.<\/p>\n<p>Whilst this issue largely pertains to eCommerce websites, there are several other common cases of page duplication:<\/p>\n<div class=\"list-styles list-styles__circle list-styles__circle--primary-color\"><ul>\n<li>Dynamic URLs for search parameters (i.e. example.com?q=green-socks) or session IDs (i.e. https:\/\/example.com?sessionid=3)<\/li>\n<li>Having unique URLs to support different device types (i.e. m.example.com for mobile)<\/li>\n<li>If your CMS automatically creates unique URLs for posts under different categories within your blog (i.e. blog.example.com\/dresses\/green-dresses\/ and blog.example.com\/green-things\/green-dresses\/)<\/li>\n<li>Configuring your server to serve the same content for www\/non-www and http\/https variants (i.e. http:\/\/example.com, https:\/\/example.com, http:\/\/www.example.com, https:\/\/www.example.com)<\/li>\n<li>Serving the same content on pages with and without a trailing slash (i.e. example.com\/dresses\/ and example.com\/dresses)<\/li>\n<li>Serving the same content on pages with capitalised\/non-capitalised URLs (i.e. example.com\/Dresses and example.com\/dresses)<\/li>\n<li>Serving pages in multiple languages &#8211; Google treats pages in different languages only if the main content is in the same language i.e. <em>\u201cif only the header, footer, and other non-critical text is translated, but the body remains the same, then the pages are considered to be duplicates\u201d<\/em><\/li>\n<\/ul>\n<\/div>\n<p>Google uses the canonical pages as the main sources to evaluate content and quality so it\u2019s crucial that you use canonical tags if you want to solve any of the duplication problems listed above.<\/p>\n<p>It\u2019s also important to note that if for example you canonicalise the desktop version of a web page, Google may still rank the mobile page if the user is on a mobile device.<\/p>\n<h3>Canonicals Common Pitfalls and Best Practices<\/h3>\n<p>Here are a few top tips and important points to take note of when using canonical tags to solve duplicate content issues.<\/p>\n<h4>Google Recommends Using Absolute URLs<\/h4>\n<p>Google\u2019s John Mueller advises you to use absolute URLs instead of relative URLs with the rel=\u201ccanonical\u201d link element.<\/p>\n<blockquote class=\"twitter-tweet\">\n<p dir=\"ltr\" lang=\"en\">You can use either, but I&#8217;d recommend using absolute URLs so that you&#8217;re sure they&#8217;re interpreted correctly.<\/p>\n<p>\u2014 \ud83c\udf4c John \ud83c\udf4c (@JohnMu) <a href=\"https:\/\/twitter.com\/JohnMu\/status\/1055155977148919808?ref_src=twsrc%5Etfw\">October 24, 2018<\/a><\/p><\/blockquote>\n<p><script async src=\"https:\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"><\/script><\/p>\n<p>For example, Google recommends that you use:<\/p>\n<pre>&lt;link rel=\u201ccanonical\u201d href=\u201chttps:\/\/example.com\/hello-world\/\u201d \/&gt;<\/pre>\n<p>Instead of:<\/p>\n<pre>&lt;link rel=\u201ccanonical\u201d href=\u201d\/hello-world\/\u201d \/&gt;<\/pre>\n<h4>Ensure The Correct Domain Version Is Used<\/h4>\n<p>Make sure that if your website is using SSL (i.e. HTTPS) any canonical tags you use do not point to non-SSL URLs as this could lead to further confusion on Google\u2019s part.<\/p>\n<p>Therefore, if your website is on a secure domain, use the following version of your URL:<\/p>\n<pre>&lt;link rel=\u201ccanonical\u201d href=\u201chttps:\/\/example.com\/hello-world\/\u201d \/&gt;<\/pre>\n<p>Instead of:<\/p>\n<pre>&lt;link rel=\u201ccanonical\u201d href=\u201chttp:\/\/example.com\/hello-world\/\u201d \/&gt;<\/pre>\n<h4>Canonicalise Your Homepage<\/h4>\n<p>Considering that one of the most common cases of duplicate content is with the homepage, a quick (but sometimes overlooked) way to solve this issue is to proactively canonicalise your homepage.<\/p>\n<h4>Self-Referential Tags Are Recommended<\/h4>\n<p>Again, coming from John Mueller, self-referential canonical tags are recommended, though not mandatory. The reason for this is because it makes it clear to Google which page you want to be indexed.<\/p>\n<p>For example, if we wanted to add a self-referential canonical tag to the page: https:\/\/example.com\/hello-world, then we would simply add the following snippet of code:<\/p>\n<pre>&lt;link rel=\u201ccanonical\u201d href=\u201chttps:\/\/example.com\/hello-world\u201d \/&gt;<\/pre>\n<p>If you\u2019re using a custom CMS (content management system), then you may need to ask your web developer to hard code this into the respective pages. However, most CMS\u2019s automatically do this for you.<\/p>\n<h4>Google Ignores Multiple Canonicals<\/h4>\n<p>This is quite an important one!<\/p>\n<p>Only one canonical tag is allowed per page. If Google encounters multiple rel=canonical tags within your web page\u2019s source code, it will <a href=\"https:\/\/webmasters.googleblog.com\/2013\/04\/5-common-mistakes-with-relcanonical.html\" target=\"_blank\" rel=\"nofollow noopener\">ignore both<\/a>.<\/p>\n<h4>Canonical Tags Should Only Appear in the &lt;head&gt;<\/h4>\n<p>A common mistake is to include the re=canonical tag in the &lt;body&gt; section, when in fact, it should go within the &lt;head&gt; of the HTML document. Any canonical tags that Google finds within the &lt;body&gt; is disregarded.<\/p>\n<p>On top of this, Google recommends adding your canonical tag as early as possible within the &lt;head&gt; to avoid any HTML parsing issues.<\/p>\n<h4>Don\u2019t Use Noindex to Prevent Canonicalisation<\/h4>\n<p>Another common mistake is to use the noindex directive to prevent Google from selecting a canonical page.<\/p>\n<p>Remember, this directive should be used if and only if you do not want Google to index your web page, it should not be used to manage which page Google chooses as the canonical one.<\/p>\n<h4>Canonicalised URLs Blocked via robots.txt<\/h4>\n<p>Remember that disallowing a URL in your robots.txt prevents Google from crawling it.<\/p>\n<p>This means that any canonical tags used on that page will not be seen by the crawler which in turn may prevent link equity being passed from the non-canonical page(s) to the canonical version.<\/p>\n<h3>Methods of Implementing Canonical Tags<\/h3>\n<p>Google outlines four different ways that you can implement canonical tags.<\/p>\n<h4>rel=canonical HTML Tag<\/h4>\n<p>This is the simplest and most common way to specify which page you want Google to treat as the canonical.<\/p>\n<p>All you need to do is add the following snippet to the &lt;head&gt; section of the HTML code:<\/p>\n<pre>&lt;link rel=\u201ccanonical\u201d href=\u201chttps:\/\/example.com\/canonical-page\/\u201d \/&gt;<\/pre>\n<h4>rel=canonical HTTP header<\/h4>\n<p>You can also use rel=&#8221;canonical&#8221; within your HTTP headers (as opposed to HTML tags) to indicate the canonical URL for any non-HTML resources such as images, PDF files, videos etc.<\/p>\n<p>For example, if you wanted to add a canonical tag to a PDF file, here\u2019s the line of code that you would need to add to the HTTP Header:<\/p>\n<pre>Link: &lt;http:\/\/www.example.com\/page\/file.pdf&gt;; rel=\"canonical\"<\/pre>\n<h4>Use a Sitemap<\/h4>\n<p>Google states that you should only include canonicalised pages in your sitemap. This is because all pages that are listed in your sitemap are seen as canonicals by Google.<\/p>\n<p>However, sometimes Google may use another URL to the ones you\u2019ve listed in the sitemap:<\/p>\n<p><em>\u201cWe don&#8217;t guarantee that we&#8217;ll consider the sitemap URLs to be canonical, but it is a simple way of defining canonicals for a large site, and sitemaps are a useful way to tell Google which pages you consider most important on your site\u201d.<\/em><\/p>\n<h4>Use 301 redirects<\/h4>\n<p>301 redirects can be used to divert traffic from duplicated URLs to the canonicalised URL.<\/p>\n<p>For example, say you have the following duplicated versions of your homepage:<\/p>\n<p>https:\/\/example.com\/home<\/p>\n<p>https:\/\/example.com<\/p>\n<p>https:\/\/www.example.com\/index.php<\/p>\n<p>You should pick the one you want to be treated as the canonical and then use 301 redirects to divert users to your preferred page.<\/p>\n<p>A 301 redirect indicates to users and search engines that the page has permanently moved to a new location.<\/p>\n<p>In this case, we may want to add a redirect from https:\/\/example.com\/home and https:\/\/www.example.com\/index.php to the canonicalised page https:\/\/example.com.<\/p>\n<h3>How to Audit Your Canonical Tags<\/h3>\n<p>There are three main questions you need to ask yourself when auditing your canonical tags<\/p>\n<p>1. Does the page have a canonical tag?<\/p>\n<p>In order to do this, simply open up the source code of your web page and look for \u201crel=\u201dcanonical\u201d\u201d.<\/p>\n<p>2. Does the canonical point to the right page?<\/p>\n<p>Make sure that the canonical is pointing to the right web page.<\/p>\n<p>3. Are the pages crawlable and indexable?<\/p>\n<p>Make sure that you haven\u2019t blocked the web pages in your robots.txt file.<\/p>\n<h2>HTTP Status Codes<\/h2>\n<p>Although they may appear to be trivial to general visitors, HTTP status codes are actually incredibly important for your SEO and should be assessed when auditing your website.<\/p>\n<h3>What are HTTP Status Codes?<\/h3>\n<p>An HTTP (HyperText Transfer Protocol) status code is a three-digit response sent to the client (i.e. a web browser or search engine bot) from the web server when its request can or cannot be fulfilled.<\/p>\n<p>When you visit a website, your browser starts a dialogue with the web server, this is referred to as a \u201chandshake\u201d within the computer science community.<\/p>\n<p>Here\u2019s how the dialogue goes:<\/p>\n<p>1. The browser sends a request to the site\u2019s web server to retrieve the web page.<\/p>\n<p>For example:<\/p>\n<pre>GET \/example.com\/academy\/hello-world\/ HTTP\/2<\/pre>\n<p>Let\u2019s break that down:<\/p>\n<div class=\"list-styles list-styles__circle list-styles__circle--primary-color\"><ul>\n<li>GET: this is the HTTP method which is used to request data from a specified resource (i.e. the web server)<\/li>\n<li>\/example.com\/academy\/hello-world\/: describes the URL that the browser has requested.<\/li>\n<li>HTTP\/2: this defines what protocol the browser and server are communicating in.<\/li>\n<\/ul>\n<\/div>\n<p>2. The server responds with a status code which is embedded within the web page\u2019s HTTP header. This tells the browser the result of the request i.e. whether the request can be fulfilled or not.<\/p>\n<p>For example, the server may send:<\/p>\n<pre>HTTP\/2 200 OK<\/pre>\n<p>Where:<\/p>\n<div class=\"list-styles list-styles__circle list-styles__circle--primary-color\"><ul>\n<li>HTTP\/2 \u2013 describes what protocol to communicate in.<\/li>\n<li>200 OK \u2013 the request was successful\u2014this is what you want to see.<\/li>\n<\/ul>\n<\/div>\n<h4>HTTP Status Code Classifications<\/h4>\n<p>These status codes are separated into the following five classes based on the different aspects of the handshake between the client and server:<\/p>\n<img loading=\"lazy\" class=\"alignnone size-full wp-image-1483\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-HTTP-status-codes.jpg\" alt=\"\" width=\"1666\" height=\"1451\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-HTTP-status-codes.jpg 1666w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-HTTP-status-codes-1536x1338.jpg 1536w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-HTTP-status-codes-386x335.jpg 386w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-HTTP-status-codes-46x40.jpg 46w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-HTTP-status-codes-92x80.jpg 92w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-HTTP-status-codes-34x30.jpg 34w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-HTTP-status-codes-69x60.jpg 69w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-HTTP-status-codes-28x24.jpg 28w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-HTTP-status-codes-55x48.jpg 55w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-HTTP-status-codes-21x18.jpg 21w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-HTTP-status-codes-41x36.jpg 41w\" sizes=\"(max-width: 1666px) 100vw, 1666px\" \/>\n<p>Fun fact: If you ever try to brew coffee in a teapot, your teapot will probably send you the status <a href=\"https:\/\/httpstatuses.com\/418\" target=\"_blank\" rel=\"nofollow noopener\">code 418<\/a>: I\u2019m a teapot.<\/p>\n<img loading=\"lazy\" class=\"alignnone size-full wp-image-1485\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-teapot.png\" alt=\"\" width=\"1274\" height=\"778\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-teapot.png 1274w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-teapot-66x40.png 66w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-teapot-131x80.png 131w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-teapot-49x30.png 49w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-teapot-98x60.png 98w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-teapot-39x24.png 39w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-teapot-79x48.png 79w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-teapot-29x18.png 29w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-teapot-59x36.png 59w\" sizes=\"(max-width: 1274px) 100vw, 1274px\" \/>\n<h3>Why Are HTTP Status Codes Important for SEO?<\/h3>\n<p>The main reason why HTTP status codes shouldn\u2019t be overlooked when it comes to SEO, is because web crawlers like Googlebot use them to determine and evaluate a website\u2019s health.<\/p>\n<p>For instance, if your website is regularly sending 5xx error codes to a search engine that is trying to index your content, this may cause several issues that will likely prevent your site from ranking to its potential.<\/p>\n<p>After all, if you want to drive organic traffic to your website (which we highlighted as being one of the main reasons why SEO is important), you need to ensure that search engines are able to crawl your content.<\/p>\n<p>Therefore, in order to be an effective SEO, it\u2019s crucial that you understand the language that is being used between your website and search engines.<\/p>\n<h3>Most Important HTTP Status Codes for SEO<\/h3>\n<p>There are <a href=\"https:\/\/httpstatuses.com\/\" target=\"_blank\" rel=\"nofollow noopener\">dozens of HTTP status codes<\/a> out there, most of which you probably will never have encountered and are outside the scope of SEO.<\/p>\n<p>Therefore, we\u2019ll only highlight the most important HTTP status codes that will have the largest impact on your SEO.<\/p>\n<h4>HTTP 200 OK<\/h4>\n<img loading=\"lazy\" class=\"alignnone size-full wp-image-1486\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-200.jpg\" alt=\"\" width=\"1780\" height=\"1068\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-200.jpg 1780w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-200-1536x922.jpg 1536w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-200-67x40.jpg 67w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-200-133x80.jpg 133w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-200-50x30.jpg 50w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-200-100x60.jpg 100w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-200-40x24.jpg 40w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-200-80x48.jpg 80w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-200-30x18.jpg 30w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-200-60x36.jpg 60w\" sizes=\"(max-width: 1780px) 100vw, 1780px\" \/>\n<p>The ideal status code you want being returned for every web page. No action needs to be taken from pages that return the HTTP 200 OK code. In this scenario, all parties are happy &#8211; the server (for providing the requested web page), the browser\/search engine (for receiving the requested web page), and of course the visitor! All messages in 2xx mean some sort of success.<\/p>\n<h4>HTTP 301 Moved Permanently<\/h4>\n<img loading=\"lazy\" class=\"alignnone size-full wp-image-1487\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-301.jpg\" alt=\"\" width=\"1780\" height=\"1068\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-301.jpg 1780w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-301-1536x922.jpg 1536w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-301-67x40.jpg 67w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-301-133x80.jpg 133w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-301-50x30.jpg 50w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-301-100x60.jpg 100w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-301-40x24.jpg 40w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-301-80x48.jpg 80w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-301-30x18.jpg 30w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-301-60x36.jpg 60w\" sizes=\"(max-width: 1780px) 100vw, 1780px\" \/>\n<p>A HTTP 301 code is sent to the client when the requested URL has permanently moved to a new location.<\/p>\n<p>This is a code that you will likely use whilst working on your website. For example, for any site migrations or other scenarios where you may need to permanently transfer SEO authority from one web page to another, this is the code to use.<\/p>\n<p>If you do not add a 301 redirect (and a visitor lands on the old page), then the browser will display a 404 error message which is something you want to avoid as it spoils the user\u2019s experience.<\/p>\n<p>On top of this, using a 301 has the added benefit of ensuring that any link authority is passed from the old URL to the new URL.<\/p>\n<h4>HTTP 302 Found \/ Moved Temporarily<\/h4>\n<img loading=\"lazy\" class=\"alignnone size-full wp-image-1488\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-302.jpg\" alt=\"\" width=\"1780\" height=\"1395\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-302.jpg 1780w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-302-1536x1204.jpg 1536w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-302-51x40.jpg 51w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-302-102x80.jpg 102w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-302-38x30.jpg 38w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-302-77x60.jpg 77w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-302-31x24.jpg 31w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-302-61x48.jpg 61w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-302-23x18.jpg 23w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-302-46x36.jpg 46w\" sizes=\"(max-width: 1780px) 100vw, 1780px\" \/>\n<p>A HTTP 302 status code means that the URL that the client has requested has been found, but that it now resides under a different URL.<\/p>\n<p>This is quite an ambiguous code as it doesn\u2019t specify whether this change is temporary or permanent. Therefore, you should only use a 302 redirect if and only if you want to temporarily redirect a URL to a different location.<\/p>\n<p>Since 302 redirects are temporary (you\u2019re effectively telling the search engine that you will revert back to the original URL at some point), no relevance or authority signals are passed between the old and new URL.<\/p>\n<p>It\u2019s also important to note that if a 302 redirect is left in place for a long time, then search engines will treat it as a 301 redirect (i.e. it is treated as a permanent redirect).<\/p>\n<h4>HTTP 303 See Other<\/h4>\n<p>A 303 redirect tells the browser or search engine crawler that the server is redirecting the requested URL to a different URL.<\/p>\n<p>This is mainly useful for preventing users from accidentally re-submitting forms more than once (i.e. when they hit the \u201cback\u201d button in their web browser) because the 303 redirect tells the browser that a follow-up request should be made to the temporary URL.<\/p>\n<p>Google\u2019s Gary Illyes confirmed that 303 redirects do pass popularity signals but that they shouldn\u2019t be used for anything except redirecting forms. This is because 303 redirects also pass link equity, but it takes much longer for this to happen than with a 301 redirect.<\/p>\n<h4>HTTP 307 Temporary Redirect \/ Internal Redirect<\/h4>\n<p>A 307 redirect is the equivalent of the 302 redirect for HTTP 1.1. A 307 redirect also lets the client (browser or search engine) know that it must NOT make any changes to the HTTP method of request if redirected to another URL.<\/p>\n<h4>HTTP 403 Forbidden<\/h4>\n<img loading=\"lazy\" class=\"alignnone size-full wp-image-1489\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-403.jpg\" alt=\"\" width=\"1606\" height=\"1098\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-403.jpg 1606w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-403-1536x1050.jpg 1536w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-403-59x40.jpg 59w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-403-117x80.jpg 117w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-403-44x30.jpg 44w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-403-88x60.jpg 88w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-403-35x24.jpg 35w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-403-70x48.jpg 70w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-403-26x18.jpg 26w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-403-53x36.jpg 53w\" sizes=\"(max-width: 1606px) 100vw, 1606px\" \/>\n<p>Simply put, a 403 code tells the browser that the user is forbidden from accessing the requested content because they do not have the correct credentials.<\/p>\n<h4 id=\"404\">HTTP 404 Not Found<\/h4>\n<img loading=\"lazy\" class=\"alignnone size-full wp-image-1490\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-404.jpg\" alt=\"\" width=\"1612\" height=\"1098\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-404.jpg 1612w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-404-1536x1046.jpg 1536w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-404-59x40.jpg 59w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-404-117x80.jpg 117w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-404-44x30.jpg 44w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-404-88x60.jpg 88w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-404-35x24.jpg 35w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-404-70x48.jpg 70w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-404-26x18.jpg 26w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-404-53x36.jpg 53w\" sizes=\"(max-width: 1612px) 100vw, 1612px\" \/>\n<p>The 404 error code is probably the most common status code that you will have encountered when browsing the web; for that reason, it\u2019s also one of the most important ones for SEO.<\/p>\n<p>A 404 Not Found status code is sent by the server when the requested resource cannot be found and has most likely been deleted.<\/p>\n<p>Avoiding 404 Not found errors is crucial in ensuring that the user\u2019s experience is as smooth as possible.<\/p>\n<p>For example, if you delete a web page, there may still be other pages that link to it. Therefore, opting for a redirect is advised (in most cases) as this way, users who click on these links (or visit the removed page directly) will be redirected to the most relevant page instead of being presented with an error message.<\/p>\n<p>On top of this having lots of 404 pages on your website may be perceived as poor maintenance by Google, which by extension, may influence your rankings. In this case, a 410 (which we\u2019ll explain next), would be more appropriate as it sends a clearer signal to Google that the page no longer exists.<\/p>\n<p>That being said, in some cases &#8211; purposely presenting the user with a 404 page is valid because it will ensure that the page is not repeatedly crawled by the search engine. To create the best possible experience, you should create a custom 404 page, which is one of the suggestions outlined in this <a href=\"https:\/\/support.google.com\/webmasters\/answer\/93641?hl=en\" target=\"_blank\" rel=\"nofollow noopener\">article from Google<\/a>.<\/p>\n<h4>HTTP 410 Gone<\/h4>\n<img loading=\"lazy\" class=\"alignnone size-full wp-image-1491\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-410.jpg\" alt=\"\" width=\"1612\" height=\"1098\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-410.jpg 1612w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-410-1536x1046.jpg 1536w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-410-59x40.jpg 59w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-410-117x80.jpg 117w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-410-44x30.jpg 44w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-410-88x60.jpg 88w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-410-35x24.jpg 35w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-410-70x48.jpg 70w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-410-26x18.jpg 26w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-410-53x36.jpg 53w\" sizes=\"(max-width: 1612px) 100vw, 1612px\" \/>\n<p>A 410 status code is an extension of the 404 error in that it indicates that content that has been requested cannot be found. However, the distinction between the two, is that a 410 code is more permanent &#8211; you\u2019re telling the client that the requested page has actually been deleted, cannot be found elsewhere and will not come back.<\/p>\n<h4>HTTP 500 Internal Server Error<\/h4>\n<img loading=\"lazy\" class=\"alignnone size-full wp-image-1493\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-500.jpg\" alt=\"\" width=\"1612\" height=\"1098\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-500.jpg 1612w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-500-1536x1046.jpg 1536w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-500-59x40.jpg 59w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-500-117x80.jpg 117w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-500-44x30.jpg 44w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-500-88x60.jpg 88w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-500-35x24.jpg 35w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-500-70x48.jpg 70w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-500-26x18.jpg 26w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-500-53x36.jpg 53w\" sizes=\"(max-width: 1612px) 100vw, 1612px\" \/>\n<p>A 500 Internal server error indicates that the server encountered an unexpected error whilst processing the request, but is unable to identify exactly what went wrong.<\/p>\n<p>We mentioned that search engines want to see that websites are being maintained, this means that you should also ensure that HTTP 500 errors are kept to a minimum &#8211; because if a crawler or user is unable to access your web page, it won\u2019t be crawled, indexed or ranked.<\/p>\n<h4>HTTP 503 Service Unavailable<\/h4>\n<img loading=\"lazy\" class=\"alignnone size-full wp-image-1494\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-503.jpg\" alt=\"\" width=\"1612\" height=\"1098\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-503.jpg 1612w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-503-1536x1046.jpg 1536w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-503-59x40.jpg 59w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-503-117x80.jpg 117w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-503-44x30.jpg 44w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-503-88x60.jpg 88w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-503-35x24.jpg 35w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-503-70x48.jpg 70w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-503-26x18.jpg 26w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-http-503-53x36.jpg 53w\" sizes=\"(max-width: 1612px) 100vw, 1612px\" \/>\n<p>A 503 error is sent by the server when it is unavailable to process the client\u2019s request. This means that whoever is trying to access the server (whether it\u2019s a user or search engine), is essentially told to come back later.<\/p>\n<p>A server may be unavailable for a number of reasons, for example it may be down for maintenance or it may be overloaded because it is unable to handle too many requests.<\/p>\n<p>If a 503 error is being sent by the server for a prolonged period of time, Google may choose to remove the content from their index.<\/p>\n<h2>Redirects<\/h2>\n<p>We briefly touched upon redirects in the HTTPS Status Codes section above, but here we\u2019ll explore the theory and practice behind redirects (specifically 301 redirects) in much more detail.<\/p>\n<h3>What are Redirects?<\/h3>\n<p>If you are changing the structure of your website, deleting pages or even moving from one domain to another, you will undoubtedly have to use redirects to do this. Redirects are a method used to divert visitors and search engines to a different URL to the one that they requested.<\/p>\n<p>Handling redirects correctly is crucial in ensuring that your website doesn\u2019t lose any rankings.Therefore, understanding what the different types of redirects are as well as knowing when to use them is incredibly important.<\/p>\n<h4>Types of Redirects<\/h4>\n<p>There are two main classifications of redirects: client-side and server-side, for the scope of this textbook, we will only focus on server-side redirects.<\/p>\n<p>A server-side redirect is where the server sends a 3xx HTTP status code to the client (browser or search engine crawler) when a URL is requested.<\/p>\n<p>The most common HTTP status codes that are relevant to SEO are:<\/p>\n<div class=\"list-styles list-styles__circle list-styles__circle--primary-color\"><ul>\n<li>301 Moved Permanently (often best for SEO)<\/li>\n<li>302 Found \/ Moved Temporarily<\/li>\n<li>303 See Other<\/li>\n<li>307 Temporary Redirect<\/li>\n<\/ul>\n<\/div>\n<p>However, for the scope of this course, we\u2019ll only look at 301 redirects because they\u2019re the type of redirect that is widely recommended within the SEO community, <a href=\"https:\/\/support.google.com\/webmasters\/answer\/93633?hl=en\" target=\"_blank\" rel=\"nofollow noopener\">and Google<\/a>.<\/p>\n<h3 id=\"301\">301 Redirects<\/h3>\n<h4>What is A 301 Redirect?<\/h4>\n<p>A 301 redirect is sent to the client when the requested URL has permanently moved to a new location. The new location is what should be used for any future requests made by a client.<\/p>\n<p>In most cases, the 301 redirect is the recommended method for implementing redirects on a website.<\/p>\n<h4>How 301 Redirects Impact SEO<\/h4>\n<p>The reason why 301 redirects are the preferred method for most redirection cases is because they pass 95-99% of the original URL\u2019s equity (ranking power) to the new URL.<\/p>\n<p>A user won\u2019t be able to tell the difference between a 301 redirect and 302 redirect (after all both redirect the user to the new page), but to search engines, the two are completely different.<\/p>\n<p>You should be careful when implementing 301 redirects because if you later decide to remove the 301 redirect, it may take weeks for Google to recrawl and reindex the URL, not to mention, the rankings for your old URL may have been lost too.<\/p>\n<p>The bottom line: once you\u2019ve implemented a 301 redirect, there\u2019s no going back.<\/p>\n<h4>When To Use a 301 Redirect<\/h4>\n<p>The circumstances where 301 redirects are particularly useful and effective are when:<\/p>\n<div class=\"list-styles list-styles__circle list-styles__circle--primary-color\"><ul>\n<li>You want to change the URL of a page or subfolder i.e. https:\/\/example.com\/home to https:\/\/example.com<\/li>\n<li>You want to move a subdomain to a subfolder i.e. https:\/\/blog.example.com to https:\/\/example.com\/blog\/<\/li>\n<li>You want to move your website to a new domain.<\/li>\n<li>You want to merge two different websites and want to ensure that the links to any outdated or deleted URLs are redirected to the correct (or most relevant) pages.<\/li>\n<li>You want to switch from HTTP to HTTPS and\/or from www. to non-www. and vice versa.<\/li>\n<\/ul>\n<\/div>\n<h4 id=\"HtIa301R\">How to Implement a 301 Redirect<\/h4>\n<p>There are several ways to implement a 301 redirect, but the most common method is to edit .htaccess file which is located in the root folder of your website.<\/p>\n<p>If you are unable to locate this file, you either simply don\u2019t have it, or, your website is hosted on a different web server that isn\u2019t Apache &#8211; i.e. it may be hosted on Windows\/IIS or Nginx.<\/p>\n<p>Also, if your website is on WordPress, we highly recommend installing this <a href=\"https:\/\/wordpress.org\/plugins\/redirection\/\" target=\"_blank\" rel=\"nofollow noopener\">free Redirection plugin<\/a>.<\/p>\n<img loading=\"lazy\" class=\"alignnone size-full wp-image-1496\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-redirection-plugin.png\" alt=\"\" width=\"1296\" height=\"490\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-redirection-plugin.png 1296w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-redirection-plugin-106x40.png 106w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-redirection-plugin-212x80.png 212w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-redirection-plugin-79x30.png 79w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-redirection-plugin-159x60.png 159w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-redirection-plugin-63x24.png 63w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-redirection-plugin-127x48.png 127w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-redirection-plugin-48x18.png 48w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-redirection-plugin-95x36.png 95w\" sizes=\"(max-width: 1296px) 100vw, 1296px\" \/>\n<p>It makes adding 301 redirects super easy (and you won\u2019t have to worry about editing the .htaccess file)!<\/p>\n<p>Before we dive into how you can go about implementing these various redirects, it\u2019s important we quickly highlight some regular expressions which we will use.<\/p>\n<img loading=\"lazy\" class=\"alignnone size-full wp-image-1497\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-301-table.jpg\" alt=\"\" width=\"1558\" height=\"1178\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-301-table.jpg 1558w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-301-table-1536x1161.jpg 1536w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-301-table-53x40.jpg 53w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-301-table-106x80.jpg 106w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-301-table-40x30.jpg 40w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-301-table-79x60.jpg 79w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-301-table-32x24.jpg 32w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-301-table-63x48.jpg 63w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-301-table-24x18.jpg 24w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-301-table-48x36.jpg 48w\" sizes=\"(max-width: 1558px) 100vw, 1558px\" \/>\n<p><u>Redirect an Old Page to a New Page<\/u><\/p>\n<p>The simplest way to redirect an old page to a new page is&#8230;<\/p>\n<pre>Redirect 301 \/old-page\/ \/new-page\/<\/pre>\n<p>\u2026 however, by omitting the regular expressions, any URLs that have a UTM query string for instance, would end up as a 404 error, which is something that we don\u2019t want.<\/p>\n<p>Therefore, we recommend the following:<\/p>\n<pre>RewriteEngine On\r\nRedirectMatch 301 ^\/old-page(\/?|\/.*)$ \/new-page\/<\/pre>\n<p>Here, the use of the regular expression \u201c^\u201d implies that the URL must start with \u201c\/old-page\u201d while (\/?|\/.*)$ indicates that anything that follows \u201c\/old-page\/\u201d with or without a forward slash \u201c\/\u201d must be redirected to \/new-page\/.<\/p>\n<p>For example, all of the following URLs will be redirected to \/new-page\/<\/p>\n<div class=\"list-styles list-styles__circle list-styles__circle--primary-color\"><ul>\n<li>\/old-page\/<\/li>\n<li>\/old-page<\/li>\n<li>\/old-page\/page-2<\/li>\n<li>\/old-page\/?sessionid=3<\/li>\n<\/ul>\n<\/div>\n<p><u>Redirect an Old Directory to a New Directory<\/u><\/p>\n<p>If you want to change the structure of an entire subfolder or directory, here\u2019s how you should go about setting up the redirect:<\/p>\n<pre>RewriteRule ^old-directory$ \/new-directory\/ [R=301,NC,L]\r\nRewriteRule ^old-directory\/(.*)$ \/new-directory\/$1 [R=301,NC,L]<\/pre>\n<p>The expression \u201c$1\u201d in the second line is used to remind the server that everything in the URL that succeeds \u201c\/old-directory\/\u201d(i.e. \/old-directory\/page-1\/) should be directed to the destination folder (i.e., \u201c\/subdirectory\/\u201d ). This way, it will be redirected to \/new-directory\/subdirectory\/.<\/p>\n<p><u>Redirect an Old Domain to a New Domain<\/u><\/p>\n<p>If you decide to shift domain names, here are the rules you should use to redirect all of the pages from your old domain, to your new domain.<\/p>\n<pre>RewriteCond %{HTTP_HOST} ^old-domain.com$ [OR]\r\nRewriteCond %{HTTP_HOST} ^www.old-domain.com$\r\nRewriteRule (.*)$ https:\/\/www.new-domain.com\/$1 [R=301,L]<\/pre>\n<p>Here, we have accounted for both the \u201cwww\u201d and \u201cnon-www\u201d versions of the URLs. This is because we want to pass any precious link authority that may be coming from internal links pointing to any of these versions of the page.<\/p>\n<p><u>Redirect From www to non-www Page<\/u><\/p>\n<p>If you simply want to redirect all www pages to non-www, use the following rules:<\/p>\n<pre>RewriteEngine on\r\nRewriteCond %{HTTP_HOST} ^example.com [NC]\r\nRewriteRule ^(.*)$ https:\/\/www.example.com\/$1 [L,R=301,NC]<\/pre>\n<p><u>Redirect From non-www to www Page<\/u><\/p>\n<p>Likewise, for non-www to www pages, use:<\/p>\n<pre>RewriteEngine on\r\nRewriteCond %{HTTP_HOST} ^www.example.com [NC]\r\nRewriteRule ^(.*)$ https:\/\/example.com\/$1 [L,R=301,NC]<\/pre>\n<p><u>Redirect From HTTP to HTTPS<\/u><\/p>\n<p>Google encourages webmasters to use SSL (for obvious reasons which we\u2019ll dive into later), so migrating websites from HTTP to HTTPS is another extremely common reason for implementing a 301 redirect.<\/p>\n<p>To force a HTTPS redirect, use the following rewrite rule:<\/p>\n<pre>RewriteCond %{HTTP_HOST} ^yourwebsite\\.com [NC,OR]\r\nRewriteCond %{HTTP_HOST} ^www\\.yourwebsite\\.com [NC]\r\nRewriteRule ^(.*)$ https:\/\/www.yourwebsite.com\/$1 [L,R=301,NC]<\/pre>\n<p>If you wanted to, you could simply use the above to combine www or non-www version redirects into a HTTPS redirect rule.<\/p>\n<h4>301 Redirects Common Pitfalls and Best Practices<\/h4>\n<p>Implementing redirects correctly is crucial to ensuring that your SEO performance is not hindered. Here are some common pitfalls to avoid and best practices to follow.<\/p>\n<p><u>Don\u2019t Redirect 404 Pages to the Homepage<\/u><\/p>\n<p>If you have too many pages that return a 404 status code, you should avoid redirecting them to the homepage.<\/p>\n<p>In fact, Google\u2019s John Mueller confirmed that Google treats these as \u201csoft 404\u2019s\u201d as it \u201cconfuses\u201d users.<\/p>\n<p>Instead, it is recommended that you create a \u201cbetter\u201d 404 page instead.<\/p>\n<blockquote class=\"twitter-tweet\">\n<p dir=\"ltr\" lang=\"en\">Yeah, it&#8217;s not a great practice (confuses users), and we mostly treat them as 404s anyway (they&#8217;re soft-404s), so there&#8217;s no upside. It&#8217;s not critically broken\/bad, but additional complexity for no good reason &#8211; make a better 404 page instead.<\/p>\n<p>\u2014 \ud83c\udf4c John \ud83c\udf4c (@JohnMu) <a href=\"https:\/\/twitter.com\/JohnMu\/status\/1082565162597605377?ref_src=twsrc%5Etfw\">January 8, 2019<\/a><\/p><\/blockquote>\n<p><script async src=\"https:\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"><\/script><\/p>\n<p>Alternatively (and this is preferred), you should aim to redirect pages that currently return 404 errors to the most relevant page possible (i.e. a page where the content is equivalent to the old page). Failing to do this not only spoils the user\u2019s experience, but you will also lose the PageRank (authority) of that page if you don\u2019t use a 301 redirect.<\/p>\n<p><u>Avoid (and Fix) Any Redirect Chains<\/u><\/p>\n<p>A redirect chain is where there is a series of redirects between the start URL and destination URL.<\/p>\n<p>Google states the following: <em>\u201cWhile Googlebot and browsers can follow a \u201cchain\u201d of multiple redirects (e.g., Page 1 &gt; Page 2 &gt; Page 3), we advise redirecting to the final destination. If this is not possible, keep the number of redirects in the chain low, ideally <u>no more than 3 and fewer than 5<\/u>.\u201d<\/em><\/p>\n<p>That being said, we would strongly advise against any redirect chains as this seriously spoils the user\u2019s experience.<\/p>\n<p>To find pages that may have multiple redirects, we recommend using this <a href=\"https:\/\/httpstatus.io\/\" target=\"_blank\" rel=\"nofollow noopener\">HTTP status checker<\/a>.<\/p>\n<p>To fix redirect chains:<\/p>\n<p>1. Implement a 301 redirect from the old URL to the destination URL.<\/p>\n<p>2. Replace any internal links that may be pointing to the old URL with the destination URL.<\/p>\n<p><u>Too Many Redirects<\/u><\/p>\n<p>In some cases, you may come across infinite redirects &#8211; this usually occurs when a regular expression is incorrect, sending the redirects into an infinite loop.<\/p>\n<p>This is the message you\u2019ll see when there are too many redirects.<\/p>\n<img loading=\"lazy\" class=\"alignnone size-full wp-image-1498\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-not-working.png\" alt=\"\" width=\"1024\" height=\"574\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-not-working.png 1024w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-not-working-650x364.png 650w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-not-working-71x40.png 71w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-not-working-143x80.png 143w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-not-working-54x30.png 54w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-not-working-107x60.png 107w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-not-working-43x24.png 43w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-not-working-86x48.png 86w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-not-working-32x18.png 32w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-not-working-64x36.png 64w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" \/>\n<p>Here\u2019s an example of what an infinite redirect loop may look like:<\/p>\n<img loading=\"lazy\" class=\"alignnone size-full wp-image-1499\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-redirect-loop.jpg\" alt=\"\" width=\"1750\" height=\"1430\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-redirect-loop.jpg 1750w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-redirect-loop-1536x1255.jpg 1536w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-redirect-loop-49x40.jpg 49w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-redirect-loop-98x80.jpg 98w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-redirect-loop-37x30.jpg 37w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-redirect-loop-73x60.jpg 73w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-redirect-loop-29x24.jpg 29w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-redirect-loop-59x48.jpg 59w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-redirect-loop-22x18.jpg 22w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-redirect-loop-44x36.jpg 44w\" sizes=\"(max-width: 1750px) 100vw, 1750px\" \/>\n<p>To find redirect loops, you can use the <a href=\"https:\/\/httpstatus.io\/\" target=\"_blank\" rel=\"nofollow noopener\">same tool<\/a>.<\/p>\n<p>To fix this issue:<\/p>\n<p>1. Change the HTTP response code to 200 if the URL is not supposed to be redirected.<\/p>\n<p>2. If the URL is supposed to redirect,then remove the loop by fixing the final destination URL (i.e. the one that is causing the loop). Likewise, remove or replace any internal links that may be pointing to the redirecting URL.<\/p>\n<p><u>Fix Any Broken Redirects<\/u><\/p>\n<p>If your redirect points to a page that returns a 404 error or 5xx error, then this is also an issue as it spoils the user experience, but from an SEO standpoint, means that the page authority of the original page is being wasted on a dead page.<\/p>\n<p>You can check for these kinds of redirects using the same HTTP status checker.<\/p>\n<p><u>Don\u2019t Use 302 Redirects or Meta Refresh for Permanent Redirects<\/u><\/p>\n<p>302 redirects should only be used for temporary redirects (i.e. you\u2019ll revert back to the original at some point). When it comes to meta refreshes (a client-side redirect), Google <a href=\"https:\/\/support.google.com\/webmasters\/answer\/79812?hl=en\" target=\"_blank\" rel=\"nofollow noopener\">advises<\/a> not to use them at all.<\/p>\n<p>If you have any of these types of redirects on your website, you should replace them with 301 redirects.<\/p>\n<p><u>Pages with a 301 Status Code Shouldn\u2019t Appear in Your Sitemap<\/u><\/p>\n<p>Remove any pages with a 301 redirect from your sitemap. Remember, your sitemap points Google in the right direction in regards to which pages it should crawl &#8211; therefore, including pages with 301 redirects has no value as they technically don\u2019t exist, so you don\u2019t want Google to crawl them. And of course, having pages like this isn\u2019t going to help with your crawl budget either.<\/p>\n<p>To solve this issue:<\/p>\n<p>1. Use this <a href=\"http:\/\/convertcsv.com\/url-extractor.htm\" target=\"_blank\" rel=\"nofollow noopener\">tool<\/a> to download the URLs from your sitemap (this can usually be found at: yourdomain.com\/sitemap.xml)<\/p>\n<p>2. Paste these URLs into this <a href=\"https:\/\/httpstatus.io\/\" target=\"_blank\" rel=\"nofollow noopener\">HTTP status checker<\/a> (you\u2019ll have to do this in batches of 100 URLs)<\/p>\n<p>3. Filter out any that return a 301 redirect.<\/p>\n<p><u>HTTP Redirects to HTTPS<\/u><\/p>\n<p>All websites should be using SSL &#8211; in fact, it\u2019s one of the <a href=\"https:\/\/webmasters.googleblog.com\/2014\/08\/https-as-ranking-signal.html\" target=\"_blank\" rel=\"nofollow noopener\">ranking signals<\/a> that Google looks at. Therefore, not just for security reasons but for SEO reasons too, it\u2019s important to ensure that all of your HTTP pages are redirected to HTTPS.<\/p>\n<p>To ensure that you\u2019re looking at the HTTPS version of a web page, simply look out for the \u201clock\u201d symbol in the URL bar at the top of your web browser.<\/p>\n<img loading=\"lazy\" class=\"alignnone size-full wp-image-1500\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-lock-symbol.png\" alt=\"\" width=\"1540\" height=\"52\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-lock-symbol.png 1540w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-lock-symbol-1536x52.png 1536w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-lock-symbol-1185x40.png 1185w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-lock-symbol-888x30.png 888w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-lock-symbol-711x24.png 711w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-lock-symbol-1422x48.png 1422w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-lock-symbol-533x18.png 533w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/08\/9-lock-symbol-1066x36.png 1066w\" sizes=\"(max-width: 1540px) 100vw, 1540px\" \/>\n<p>If you type in \u201chttp:\/\/yourdomain.com\u201d, you should be redirected to \u201chttps:\/\/yourdomain.com\u201d.<\/p>\n<p>If not, then the redirect is not in place.<\/p>\n<p><u>Merge Similar Pages<\/u><\/p>\n<p>This one\u2019s quite important (and powerful). If you have two pages that are topically related and neither are quite hitting the mark in terms of ranking, a powerful approach is to combine the contents of these pages into a single page, and then implement a 301 redirect from the page which isn\u2019t performing as well, to the one that performs better.<\/p>\n<p>Let\u2019s illustrate this via an example:<\/p>\n<p>We have two pages which highlight the best earphones, but one purely focuses on wireless earphones.<\/p>\n<p>Page 1: https:\/\/example.com\/best-earphones<br \/>\nNumber of Organic Visits per Month: 2000<\/p>\n<p>Page 2: https:\/\/example.com\/best-wireless-earphones<br \/>\nNumber of Organic Visits per Month: 175<\/p>\n<p>Both pages have similar content and are topically related, but only Page 1 is receiving a decent amount of traffic per month.<\/p>\n<p>Therefore, we would simply add the content from Page 2 to Page 1 under a heading like \u201cBest Wireless Earphones\u201d, and then implement a 301 redirect from Page 2 to Page 1.<\/p>\n<p>This way, we aren\u2019t losing any of Page 2\u2019s ranking power and are boosting the potential of Page 1\u2019s organic traffic at the same time.<\/p>\n"},"_links":{"self":[{"href":"https:\/\/susodigital.com\/textbook\/wp-json\/wp\/v2\/modules\/1466"}],"collection":[{"href":"https:\/\/susodigital.com\/textbook\/wp-json\/wp\/v2\/modules"}],"about":[{"href":"https:\/\/susodigital.com\/textbook\/wp-json\/wp\/v2\/types\/module"}],"version-history":[{"count":19,"href":"https:\/\/susodigital.com\/textbook\/wp-json\/wp\/v2\/modules\/1466\/revisions"}],"predecessor-version":[{"id":1966,"href":"https:\/\/susodigital.com\/textbook\/wp-json\/wp\/v2\/modules\/1466\/revisions\/1966"}],"up":[{"embeddable":true,"href":"https:\/\/susodigital.com\/textbook\/wp-json\/wp\/v2\/modules\/410"}],"wp:attachment":[{"href":"https:\/\/susodigital.com\/textbook\/wp-json\/wp\/v2\/media?parent=1466"}],"curies":[{"name":"wp","href":"https:\/\/api.w.org\/{rel}","templated":true}]}}