{"id":951,"date":"2020-07-20T16:00:36","date_gmt":"2020-07-20T15:00:36","guid":{"rendered":"https:\/\/susodigital.com\/textbook\/?post_type=module&#038;p=951"},"modified":"2020-09-28T10:04:51","modified_gmt":"2020-09-28T09:04:51","slug":"lsi-compound-keywords","status":"publish","type":"module","link":"https:\/\/susodigital.com\/textbook\/module\/semantic-search\/lsi-compound-keywords","title":{"rendered":"Latent Semantic Indexing and Compound Keywords"},"featured_media":0,"parent":393,"menu_order":27,"template":"","acf":{"module_quiz":"","module_time":"38","module_difficulty":{"value":"hard","label":"Hard"},"module_short_description":"<p>Uncover the mysteries of Latent Semantic Indexing and Compound Keywords.<\/p>\n","module_long_description":"<p>In this chapter, we uncover the mysteries of latent semantic indexing and how it may or may not be used by Google's algorithm.<\/p>\n","video_file":false,"video_url":"","content":"<p>In this section, we\u2019ll explore the concept of latent semantic indexing (and keywords), compound keywords and how they may or may not improve your SEO efforts.<\/p>\n<h2>What Are LSI Keywords?<\/h2>\n<p>LSI keywords (within the SEO community) are words or phrases that search engines like Google see as being semantically (or conceptually) related.<\/p>\n<p>It\u2019s worth noting LSI keywords are not direct synonyms (more on synonyms later), but instead, are terms that are closely related to the keyword that you are trying to target.<\/p>\n<p>For example, if you\u2019re writing an article about football, then a synonym would be \u201csoccer\u201d, but LSI keywords would be ball, pitch, referee, striker, defender, midfield etc.<\/p>\n<p>That being said, Google\u2019s John Mueller says they don\u2019t exist.<\/p>\n<blockquote class=\"twitter-tweet\">\n<p dir=\"ltr\" lang=\"en\">There&#8217;s no such thing as LSI keywords &#8212; anyone who&#8217;s telling you otherwise is mistaken, sorry.<\/p>\n<p>\u2014 \ud83c\udf4c John \ud83c\udf4c (@JohnMu) <a href=\"https:\/\/twitter.com\/JohnMu\/status\/1156293862681468929?ref_src=twsrc%5Etfw\">July 30, 2019<\/a><\/p><\/blockquote>\n<p><script async src=\"https:\/\/platform.twitter.com\/widgets.js\" charset=\"utf-8\"><\/script><\/p>\n<p>But if Google is saying that LSI keywords aren\u2019t important, why mention them at all?<\/p>\n<p>In order to understand this, let\u2019s take a closer look at LSI.<\/p>\n<h3>What Is Latent Semantic Indexing?<\/h3>\n<p>Latent Semantic Indexing is a concept that is talked about a lot in the SEO community and pretty much every article you\u2019ll read boils down to these two things:<\/p>\n<ol>\n<li>Google uses LSI to index pages on the web.<\/li>\n<li>If you use LSI keywords in your content, you will have a higher chance of ranking on Google<\/li>\n<\/ol>\n<p>Both of these statements aren&#8217;t exactly true.<\/p>\n<p>So, let\u2019s take a look at what LSI actually is.<\/p>\n<p>Latent Semantic Indexing is a natural language processing technique that predates not only SEO, but the Web itself. It was invented by Microsoft\u2019s Susan Dumais in the late 1980\u2019s with the aim of indexing contents of document collections that remained static &#8211; i.e. they were unlikely to change. Dumais was granted a patent as the co-inventor of the Latent Semantic Indexing process in 1989 titled \u201c<a href=\"https:\/\/www.lens.org\/lens\/patent\/071-607-562-364-305\" target=\"_blank\" rel=\"noopener\">Computer information retrieval using latent semantic structure<\/a>\u201d.<\/p>\n<p>Here\u2019s how the creators of the patent define the problem that they were trying to solve at the time:<\/p>\n<blockquote class=\"blockquote d-flex align-items-center bg-suso-white text-dark-blue line-height-1-5\"><svg class=\"blockquote__icon d-block\" enable-background=\"new 0 0 34 29\" viewBox=\"0 0 34 29\" xmlns=\"http:\/\/www.w3.org\/2000\/svg\"><g fill=\"#18217e\" opacity=\".5\"><path d=\"m10.6 13.1c-.8-.2-1.6-.4-2.4-.4-1.2 0-2.2.3-3 .7.8-2.9 2.6-8 6.2-8.5.3-.1.6-.4.6-.7l.8-3c.1-.3 0-.5-.1-.7s-.4-.4-.6-.4c-.2-.1-.5-.1-.8-.1-4.4 0-8.7 4.8-10.5 11.6-1.1 4-1.4 10.1 1.3 13.9 1.5 2.1 3.6 3.3 6.4 3.4 3.4 0 6.5-2.4 7.4-5.9.6-2.1.3-4.2-.7-6.1s-2.7-3.2-4.6-3.8z\"\/><path d=\"m33 16.9c-1-1.9-2.6-3.2-4.6-3.8-.8-.2-1.6-.4-2.4-.4-1.2 0-2.2.3-3 .7.8-2.9 2.6-8 6.2-8.5.3-.1.6-.3.7-.7l.8-3c.1-.3 0-.5-.1-.7s-.4-.4-.6-.4c-.3-.1-.6-.1-.8-.1-4.4 0-8.7 4.8-10.5 11.6-1.1 4-1.4 10.1 1.3 13.9 1.5 2.1 3.6 3.3 6.4 3.4 3.4 0 6.5-2.4 7.4-5.9.5-2.1.2-4.2-.8-6.1z\"\/><\/g><\/svg><div><div class=\"entry-content\">\u201cBecause human word use is characterized by extensive synonymy and polysemy, straightforward term-matching schemes have serious shortcomings\u2013relevant materials will be missed because different people describe the same topic using different words and, because the same word can have different meanings, the irrelevant material will be retrieved. The basic problem may be simply summarized by stating that people want to access information based on meaning, but the words they select do not adequately express intended meaning.\u201d<\/div><\/div><\/blockquote>\n<p>In simpler terms, \u201c<em><strong>The words a searcher uses are often not the same as those by which the information sought has been indexed.<\/strong><\/em>\u201d<\/p>\n<p>A quote from the great J. R. R. Tolkien comes to mind: \u201c<em>Do you wish me a good morning, or mean that it is a good morning whether I want it or not; or that you feel good this morning; or that it is a morning to be good on?<\/em>\u201d.<\/p>\n<p>In the above example, the word \u201cgood\u201d has multiple meanings &#8211; it\u2019s a synonym and polysemic word.<\/p>\n<h4>What are synonyms?<\/h4>\n<p>A synonym (as defined by the instant answer from a Google search), is \u201c<em>a word or phrase that means exactly or nearly the same as another word or phrase in the same language, for example shut is a synonym of close<\/em>\u201d.<\/p>\n<img loading=\"lazy\" class=\"aligncenter size-full wp-image-953\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Define-synonym.png\" alt=\"Define synonym\" width=\"922\" height=\"796\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Define-synonym.png 922w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Define-synonym-46x40.png 46w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Define-synonym-93x80.png 93w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Define-synonym-35x30.png 35w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Define-synonym-69x60.png 69w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Define-synonym-28x24.png 28w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Define-synonym-56x48.png 56w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Define-synonym-21x18.png 21w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Define-synonym-42x36.png 42w\" sizes=\"(max-width: 922px) 100vw, 922px\" \/>\n<p>Synonyms of the word \u201clucky\u201d would be: auspicious and fortunate.<\/p>\n<p>Synonyms are troublesome because \u201c<em>Users in different contexts, or with different needs, knowledge or linguistic habits will describe the same information using different terms.<\/em>\u201d<\/p>\n<h4>What are polysemic words?<\/h4>\n<p>Polysemic words and phrases are those that have many different meanings, for example, the word \u201cbass\u201d could mean:<\/p>\n<ol>\n<li>The fish<\/li>\n<li>A deep, low voice<\/li>\n<\/ol>\n<img loading=\"lazy\" class=\"aligncenter size-full wp-image-954\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-What-are-polysemic-words-.jpg\" alt=\"What are polysemic words? Example of &quot;bass&quot;\" width=\"1674\" height=\"1256\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-What-are-polysemic-words-.jpg 1674w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-What-are-polysemic-words--1536x1152.jpg 1536w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-What-are-polysemic-words--53x40.jpg 53w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-What-are-polysemic-words--107x80.jpg 107w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-What-are-polysemic-words--40x30.jpg 40w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-What-are-polysemic-words--80x60.jpg 80w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-What-are-polysemic-words--32x24.jpg 32w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-What-are-polysemic-words--64x48.jpg 64w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-What-are-polysemic-words--24x18.jpg 24w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-What-are-polysemic-words--48x36.jpg 48w\" sizes=\"(max-width: 1674px) 100vw, 1674px\" \/>\n<p>The patent explains why polysemic words also pose issues when it comes to LSI.<\/p>\n<blockquote class=\"blockquote d-flex align-items-center bg-suso-white text-dark-blue line-height-1-5\"><svg class=\"blockquote__icon d-block\" enable-background=\"new 0 0 34 29\" viewBox=\"0 0 34 29\" xmlns=\"http:\/\/www.w3.org\/2000\/svg\"><g fill=\"#18217e\" opacity=\".5\"><path d=\"m10.6 13.1c-.8-.2-1.6-.4-2.4-.4-1.2 0-2.2.3-3 .7.8-2.9 2.6-8 6.2-8.5.3-.1.6-.4.6-.7l.8-3c.1-.3 0-.5-.1-.7s-.4-.4-.6-.4c-.2-.1-.5-.1-.8-.1-4.4 0-8.7 4.8-10.5 11.6-1.1 4-1.4 10.1 1.3 13.9 1.5 2.1 3.6 3.3 6.4 3.4 3.4 0 6.5-2.4 7.4-5.9.6-2.1.3-4.2-.7-6.1s-2.7-3.2-4.6-3.8z\"\/><path d=\"m33 16.9c-1-1.9-2.6-3.2-4.6-3.8-.8-.2-1.6-.4-2.4-.4-1.2 0-2.2.3-3 .7.8-2.9 2.6-8 6.2-8.5.3-.1.6-.3.7-.7l.8-3c.1-.3 0-.5-.1-.7s-.4-.4-.6-.4c-.3-.1-.6-.1-.8-.1-4.4 0-8.7 4.8-10.5 11.6-1.1 4-1.4 10.1 1.3 13.9 1.5 2.1 3.6 3.3 6.4 3.4 3.4 0 6.5-2.4 7.4-5.9.5-2.1.2-4.2-.8-6.1z\"\/><\/g><\/svg><div><div class=\"entry-content\">\u201cIn different contexts or when used by different people the same word takes on varying referential significance (e.g., \u201cbank\u201d in river bank versus \u201cbank\u201d in a savings bank). Thus the use of a term in a search query does not necessarily mean that a text object containing or labeled by the same term is of interest.\u201d<\/div><\/div><\/blockquote>\n<h3>How Does LSI Relate to SEO?<\/h3>\n<p>Let&#8217;s take a look at how search engines could use LSI to solve the problems caused by synonyms and polysemic words.<\/p>\n<p>If we have two identical web pages that are about chairs, but one substitutes the word \u201cchair\u201d for \u201cseat\u201d.<\/p>\n<p>A search engine that was unable to identify that \u201cchair\u201d and \u201cseat\u201d are synonymous, would only return one of these pages for the query \u201cchairs\u201d.<\/p>\n<img loading=\"lazy\" class=\"aligncenter size-full wp-image-955\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-How-Does-LSI-Relate-to-SEO-1.jpg\" alt=\"How Does LSI Relate to SEO\" width=\"1481\" height=\"1130\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-How-Does-LSI-Relate-to-SEO-1.jpg 1481w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-How-Does-LSI-Relate-to-SEO-1-52x40.jpg 52w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-How-Does-LSI-Relate-to-SEO-1-105x80.jpg 105w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-How-Does-LSI-Relate-to-SEO-1-39x30.jpg 39w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-How-Does-LSI-Relate-to-SEO-1-79x60.jpg 79w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-How-Does-LSI-Relate-to-SEO-1-31x24.jpg 31w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-How-Does-LSI-Relate-to-SEO-1-63x48.jpg 63w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-How-Does-LSI-Relate-to-SEO-1-24x18.jpg 24w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-How-Does-LSI-Relate-to-SEO-1-47x36.jpg 47w\" sizes=\"(max-width: 1481px) 100vw, 1481px\" \/>\n<p>Similarly, polysemic words like \u201cbank\u201d would return results that perhaps aren\u2019t what the searcher is looking for &#8211; the search engine is not able to determine whether you are looking for \u201criverbank\u201d or \u201cinstitutional bank\u201d.<\/p>\n<img loading=\"lazy\" class=\"aligncenter size-full wp-image-956\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-How-Does-LSI-Relate-to-SEO-2.jpg\" alt=\"bank vs riverbank vs intitutional bank - polysemic keywords\" width=\"1539\" height=\"1130\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-How-Does-LSI-Relate-to-SEO-2.jpg 1539w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-How-Does-LSI-Relate-to-SEO-2-1536x1128.jpg 1536w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-How-Does-LSI-Relate-to-SEO-2-54x40.jpg 54w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-How-Does-LSI-Relate-to-SEO-2-109x80.jpg 109w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-How-Does-LSI-Relate-to-SEO-2-41x30.jpg 41w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-How-Does-LSI-Relate-to-SEO-2-82x60.jpg 82w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-How-Does-LSI-Relate-to-SEO-2-33x24.jpg 33w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-How-Does-LSI-Relate-to-SEO-2-65x48.jpg 65w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-How-Does-LSI-Relate-to-SEO-2-25x18.jpg 25w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-How-Does-LSI-Relate-to-SEO-2-49x36.jpg 49w\" sizes=\"(max-width: 1539px) 100vw, 1539px\" \/>\n<p>The bottom line is that computers simply do not have the inherent understanding of semantic relationships between words that we humans do. A simple solution would be to tell the computer everything, but this would take a very, very long time to do and is unfeasible.<\/p>\n<p>LSI helps solve this problem by using sophisticated mathematical formulae which derive the semantic relationships between words and phrases within a piece of text. This means that search engines are able to distinguish polysemic words and match synonyms to present more relevant search results to the user.<\/p>\n<h3>Does Google Use LSI?<\/h3>\n<p>Many SEOs claim that Google is using Latent Semantic Indexing, but what they really mean when they say this, is that Google is using synonyms and polysemic words in its algorithm.<\/p>\n<p>On the surface, this appears to be correct &#8211; after all, if we search for the keyword \u201cautomobile\u201d, we can see that Google returns the Wikipedia entry for \u201cCar\u201d as the first result.<\/p>\n<img loading=\"lazy\" class=\"aligncenter size-full wp-image-957\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Automobile-vs-car-example.png\" alt=\"Automobile vs car example\" width=\"1082\" height=\"439\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Automobile-vs-car-example.png 1082w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Automobile-vs-car-example-99x40.png 99w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Automobile-vs-car-example-197x80.png 197w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Automobile-vs-car-example-74x30.png 74w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Automobile-vs-car-example-148x60.png 148w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Automobile-vs-car-example-59x24.png 59w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Automobile-vs-car-example-118x48.png 118w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Automobile-vs-car-example-44x18.png 44w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Automobile-vs-car-example-89x36.png 89w\" sizes=\"(max-width: 1082px) 100vw, 1082px\" \/>\n<p>Likewise, searching the polysemic term \u201cmouse\u201d, shows that Google is able to understand the difference between a computer mouse and the rodent.<\/p>\n<img loading=\"lazy\" class=\"aligncenter size-full wp-image-958\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-mouse-vs-computer-mouse-example.png\" alt=\"mouse vs computer mouse - example\" width=\"1540\" height=\"840\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-mouse-vs-computer-mouse-example.png 1540w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-mouse-vs-computer-mouse-example-1536x838.png 1536w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-mouse-vs-computer-mouse-example-73x40.png 73w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-mouse-vs-computer-mouse-example-147x80.png 147w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-mouse-vs-computer-mouse-example-55x30.png 55w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-mouse-vs-computer-mouse-example-110x60.png 110w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-mouse-vs-computer-mouse-example-44x24.png 44w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-mouse-vs-computer-mouse-example-88x48.png 88w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-mouse-vs-computer-mouse-example-33x18.png 33w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-mouse-vs-computer-mouse-example-66x36.png 66w\" sizes=\"(max-width: 1540px) 100vw, 1540px\" \/>\n<p>Whilst Google is definitely looking at synonyms and polysemic words to derive semantic relationships, it does not mean that LSI is being used.<\/p>\n<p>In fact, we\u2019ve already seen that Google use <a href=\"https:\/\/susodigital.com\/textbook\/module\/how-google-works\/the-indexing-phase\" target=\"_blank\" rel=\"noopener\">Word Vectors to index the content<\/a> on a web page.<\/p>\n<p>On top of this, Google representatives themselves have quashed any insinuations that LSI is part of the algorithm &#8211; we saw John Mueller debunk LSI keywords altogether earlier.<\/p>\n<h2>Semantic Topic Clustering and Phrase Based Indexing<\/h2>\n<p>This section is for those of you who want to know more about how the latent semantic analysis in natural language processing works, and how Google uses techniques called semantic topic modelling and phrase based indexing to achieve this.<\/p>\n<p>Before we dive into the nitty gritty details, let\u2019s take a brief step back and look at what the Latent Semantic Analysis model is. The LSA model theorises how sentiment behind natural language may be learned by a machine without any direction or help from a human as to its structure.<\/p>\n<p>In order to understand patterns from text, LSA follows the following assumptions:<\/p>\n<ol>\n<li>The meaning of sentences is defined as the sum of the meaning of all of the words that appear within it.<\/li>\n<li>The model assumes that the semantic relationships between different words within a sentence are not explicit, but are latent in the sample of language.<\/li>\n<\/ol>\n<h3>Semantic Topic Modelling<\/h3>\n<p>The LSA model takes into account several mathematical formulae to get an idea of the sentiment behind a document of text and is based on the concept of semantic topic modelling.<\/p>\n<p>Semantic topic modelling (or semantic topic clustering) is a machine learning technique used to scan a set of documents to detect patterns between the words and phrases, and automatically form word groups and similar expressions that best summarise the set of documents.<\/p>\n<p>A scientific paper from Google titled \u201c<a href=\"http:\/\/www.cs.utexas.edu\/~inderjit\/public_papers\/kdd_bipartite.pdf\" target=\"_blank\" rel=\"noopener\">Improving semantic topic clustering for search queries with word co-occurrence and bipartite graph co-clustering<\/a>\u201d provides insights into how Google is able to categorise search queries into topic clusters through two techniques: Word Co-Occurrence Clustering and Weighted Bigraph Clustering.<\/p>\n<p>The paper explains how information from search queries can help provide interesting and helpful insights for businesses.<\/p>\n<p>For example, knowing the search volume for particular products or brands tells you the number of people that are interested in those products. Likewise, this also tells you what people may associate with those brands &#8211; i.e. topics which in turn informs the creation of categories i.e. clustering beauty products into a single category.<\/p>\n<p>However, one of the drawbacks of trying to learn from topics using this method, is that most search queries tend to be very short, which means that the number of other terms that appear \u201cnear\u201d them (i.e. related terms) becomes very restricted.<\/p>\n<p>For instance, the word \u201cMars\u201d might show up frequently near words that are related to \u201cplanets\u201d and to \u201cchocolate\u201d.<\/p>\n<img loading=\"lazy\" class=\"aligncenter size-full wp-image-959\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Semantic-Topic-Modelling.jpg\" alt=\"Semantic Topic Modelling\" width=\"1446\" height=\"1256\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Semantic-Topic-Modelling.jpg 1446w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Semantic-Topic-Modelling-386x335.jpg 386w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Semantic-Topic-Modelling-772x670.jpg 772w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Semantic-Topic-Modelling-46x40.jpg 46w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Semantic-Topic-Modelling-92x80.jpg 92w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Semantic-Topic-Modelling-35x30.jpg 35w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Semantic-Topic-Modelling-69x60.jpg 69w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Semantic-Topic-Modelling-28x24.jpg 28w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Semantic-Topic-Modelling-55x48.jpg 55w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Semantic-Topic-Modelling-21x18.jpg 21w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Semantic-Topic-Modelling-41x36.jpg 41w\" sizes=\"(max-width: 1446px) 100vw, 1446px\" \/>\n<h3>Word Co-Occurrence Clustering<\/h3>\n<p>Word Co-Occurrence looks at when the same terms or phrases appear frequently in documents that rank highly for a search query. For example, when the term &#8220;strong coffee&#8221; appears in a web page, the term &#8220;espresso bean&#8221; probably also tends to occur. This means that these words or phrases are likely to be semantically related to the terms that they rank highly for.<\/p>\n<p>Word co-occurrence clustering is defined by the following formula which assigns each cluster a \u201clift score\u201d or weight.<\/p>\n<img loading=\"lazy\" class=\"aligncenter size-full wp-image-960\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Lift-Score-Word-Co-Occurrence-Clustering.jpg\" alt=\"Lift Score - Word Co-Occurrence Clustering\" width=\"1746\" height=\"1282\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Lift-Score-Word-Co-Occurrence-Clustering.jpg 1746w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Lift-Score-Word-Co-Occurrence-Clustering-1536x1128.jpg 1536w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Lift-Score-Word-Co-Occurrence-Clustering-54x40.jpg 54w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Lift-Score-Word-Co-Occurrence-Clustering-109x80.jpg 109w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Lift-Score-Word-Co-Occurrence-Clustering-41x30.jpg 41w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Lift-Score-Word-Co-Occurrence-Clustering-82x60.jpg 82w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Lift-Score-Word-Co-Occurrence-Clustering-33x24.jpg 33w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Lift-Score-Word-Co-Occurrence-Clustering-65x48.jpg 65w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Lift-Score-Word-Co-Occurrence-Clustering-25x18.jpg 25w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Lift-Score-Word-Co-Occurrence-Clustering-49x36.jpg 49w\" sizes=\"(max-width: 1746px) 100vw, 1746px\" \/>\n<p>If for example the lift score is 5, then the probability of the query wi being searched for, given the action a, is five times higher than the general likelihood of wi being searched for.<\/p>\n<p>The paper states that \u201cA large lift score helps us to construct topics around meaningful rather than uninteresting words. In practice the probabilities can be estimated using word frequency in Google search history within a recent time window.\u201d<\/p>\n<p>This is represented by a <strong>co-occurrence matrix<\/strong>, which if you haven\u2019t guessed already, is another <a href=\"http:\/\/patft.uspto.gov\/netacgi\/nph-Parser?Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PALL&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.htm&amp;r=1&amp;f=G&amp;l=50&amp;s1=8,321,409.PN.&amp;OS=PN\/8,321,409&amp;RS=PN\/8,321,409\" target=\"_blank\" rel=\"noopener\">patented technology granted to Google<\/a>.<\/p>\n<p>To generate the co-occurrence matrix, Google uses a similar method to Tf-IDF Vectorisation.<\/p>\n<p>Given m documents, and n-words in the vocabulary, an m x n matrix can be constructed where each row represents a document, and each column represents a word.<\/p>\n<p>Tf-IDF (which stands for Term Frequency- Inverse Document Frequency) is a technique used by search engines to retrieve information about a piece of text and weighs a term\u2019s (or word\u2019s) frequency (Tf) and its inverse document frequency (IDF). In other words, each word or term is assigned its own TF and IDF score, and the product of these two values returns its TF*IDF weight.<\/p>\n<p>The higher the TF*IDF score (weight), the less often the term appears in the content (and vice versa)..<\/p>\n<p>Here\u2019s the formula for TF*IDF:<\/p>\n<p>For a term <strong>t<\/strong> in document <strong>d<\/strong>, the weight <strong>Wt,d<\/strong> of term <strong>t<\/strong> in document <strong>d<\/strong> is:<\/p>\n<img loading=\"lazy\" class=\"aligncenter size-full wp-image-961\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-TF-IDF-Word-Co-Occurrence-Clustering-copy.jpg\" alt=\"TF-IDF Formula - Word Co-Occurrence Clustering \" width=\"1746\" height=\"1282\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-TF-IDF-Word-Co-Occurrence-Clustering-copy.jpg 1746w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-TF-IDF-Word-Co-Occurrence-Clustering-copy-1536x1128.jpg 1536w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-TF-IDF-Word-Co-Occurrence-Clustering-copy-54x40.jpg 54w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-TF-IDF-Word-Co-Occurrence-Clustering-copy-109x80.jpg 109w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-TF-IDF-Word-Co-Occurrence-Clustering-copy-41x30.jpg 41w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-TF-IDF-Word-Co-Occurrence-Clustering-copy-82x60.jpg 82w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-TF-IDF-Word-Co-Occurrence-Clustering-copy-33x24.jpg 33w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-TF-IDF-Word-Co-Occurrence-Clustering-copy-65x48.jpg 65w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-TF-IDF-Word-Co-Occurrence-Clustering-copy-25x18.jpg 25w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-TF-IDF-Word-Co-Occurrence-Clustering-copy-49x36.jpg 49w\" sizes=\"(max-width: 1746px) 100vw, 1746px\" \/>\n<p>Let\u2019s go through an example.<\/p>\n<p>If our web page has 200 words, and it mentioned the word \u201cdog\u201d 20 times, the TF for the word \u201cdog\u201d is:<\/p>\n<p>TFdog = 20\/200 i.e. 0.10.<\/p>\n<p>Now, let\u2019s say the term \u201cdog\u201d appears x amount of times in a 1,000,000 million document-sized corpus (i.e. the big wide web) and let\u2019s assume that there are 250,000 documents that contain the term \u201cdog\u201d.<\/p>\n<p>Then, the IDF (which measures how significant that term is in the whole corpus) is given by the total number of documents (1,000,000) divided by the number of documents containing the term \u201cdog\u201d (250,000).<\/p>\n<p>IDF (dog) = log (1,000,000\/250,000) = 0.60<\/p>\n<p>Therefore, Wdog = 0.10 (TF) * 0.60 (IDF) = 0.06<\/p>\n<p>If we did the same for the word \u201cpuppy\u201d and found that the TF*IDF is 0.10, then we can infer that the term \u201cdog\u201d appears more frequently than \u201cpuppy\u201d because it has a lower TF*IDF weight.<\/p>\n<p>By applying this formula to each word within the document (or query), we form our co-occurrence matrix.<\/p>\n<p>With these vectors (matrices), the model is able to apply measures like cosine similarity to essentially calculate the \u201cdistance\u201d between them.<\/p>\n<p>So for example, if two vectors have a smaller cosine similarity, then the algorithm infers that they are topically related.<\/p>\n<p>Google uses the lift score to \u201crank the words by importance and then threshold it to obtain a set of words highly associated with the context.\u201d<\/p>\n<p>According to Google\u2019s tests, this method works well when \u201c<em>the queries are closely related, e.g. brand queries, so that the keywords expansion step can effectively extrapolate the scope of words to reach broader topics<\/em>\u201d.<\/p>\n<p>However, if <strong>wi<\/strong> is not defined clearly, then the second method is applied: <strong>weighted bigraph clustering<\/strong>.<\/p>\n<h3>Weighted Bigraph Clustering<\/h3>\n<p>The bigraph clustering method involves taking words and phrases from many web pages that already rank for a particular search term, and combining them to pull out phrases that appear within these documents. These words\/phrases are then clustered into groups based on how frequently they appear within the documents.<\/p>\n<p>Weighted bigraph clustering is based on the following assumptions:<\/p>\n<ol>\n<li>\u201cUsers may phrase their query differently, including variations and misspellings, but a search engine understands they are close and present the same URL to the users. Hence, URLs can identify queries of similar meaning\u201d.<\/li>\n<li>\u201cURLs that are shown as top search results for a single query are somewhat similar. Hence, queries naturally group similar URLs to together\u201d.<\/li>\n<\/ol>\n<p>With this method, the search queries are compared against the top ranking web pages where query-URL pairs are created. These pairs are weighted according to users\u2019 CTR (click through rates) and page impressions which allows the algorithm to identify similarities between the core keyword and related terms and therefore, create semantically related clusters.<\/p>\n<img loading=\"lazy\" class=\"aligncenter size-full wp-image-962\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Example-semantic-clusters-for-lipton-brand-queries-using-bigraph-clustering.jpg\" alt=\"Example semantic clusters for lipton brand queries using bigraph clustering\" width=\"1544\" height=\"2092\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Example-semantic-clusters-for-lipton-brand-queries-using-bigraph-clustering.jpg 1544w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Example-semantic-clusters-for-lipton-brand-queries-using-bigraph-clustering-1134x1536.jpg 1134w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Example-semantic-clusters-for-lipton-brand-queries-using-bigraph-clustering-1512x2048.jpg 1512w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Example-semantic-clusters-for-lipton-brand-queries-using-bigraph-clustering-30x40.jpg 30w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Example-semantic-clusters-for-lipton-brand-queries-using-bigraph-clustering-59x80.jpg 59w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Example-semantic-clusters-for-lipton-brand-queries-using-bigraph-clustering-22x30.jpg 22w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Example-semantic-clusters-for-lipton-brand-queries-using-bigraph-clustering-44x60.jpg 44w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Example-semantic-clusters-for-lipton-brand-queries-using-bigraph-clustering-18x24.jpg 18w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Example-semantic-clusters-for-lipton-brand-queries-using-bigraph-clustering-35x48.jpg 35w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Example-semantic-clusters-for-lipton-brand-queries-using-bigraph-clustering-13x18.jpg 13w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Example-semantic-clusters-for-lipton-brand-queries-using-bigraph-clustering-27x36.jpg 27w\" sizes=\"(max-width: 1544px) 100vw, 1544px\" \/>\n<p>Above, is an example from the paper of semantic clusters for \u201cLipton\u201d brand related queries using bigraph clustering.<\/p>\n<p>This method is great for grouping queries that are semantically close together because it utilises the information that is embedded into Google\u2019s search results. As a result of this, weighted bigraph clustering is able to perform much better than word co-occurrence clustering even if the queries do not share any common words.<\/p>\n<p>In summary, the two methods outlined above describe how Google can better understand topics that may be related.<\/p>\n<h2 id=\"CK\">Compound Keywords<\/h2>\n<p>The term \u201cLSI keywords\u201d, as we\u2019ve seen in the introduction to this section, is a little misleading as it doesn\u2019t exactly exist. When SEOs talk about \u201cLSI keywords\u201d, what they are essentially referring to are the related words, phrases, and entities to the keyword you want to target,<\/p>\n<p>Therefore at SUSO, we like to call these \u201ccompound keywords\u201d instead.<\/p>\n<p>We like to define compound keywords as keywords that are related, but do not necessarily include direct terms.<\/p>\n<p>Examples of compound keywords would be questions, and topical phrases that relate to the core keyword that you are trying to target.<\/p>\n<p>Including compound keywords within your text, will almost definitely improve your site\u2019s search presence.<\/p>\n<p>One of the reasons for this is the fact that we know from previous modules that <a href=\"https:\/\/susodigital.com\/textbook\/module\/google-algorithms\/algo-updates\">RankBrain and Neural Matching<\/a>, along with <a href=\"https:\/\/susodigital.com\/textbook\/module\/google-algorithms\/google-cleverness\">Natural Language Processing<\/a> techniques, help Google gain a better understanding of concepts and topics within a piece of content.<\/p>\n<p>In fact, this is also evident from <a href=\"https:\/\/www.google.com\/search\/howsearchworks\/algorithms\/\" target=\"_blank\" rel=\"noopener\">this article published by Google<\/a>:<\/p>\n<blockquote class=\"blockquote d-flex align-items-center bg-suso-white text-dark-blue line-height-1-5\"><svg class=\"blockquote__icon d-block\" enable-background=\"new 0 0 34 29\" viewBox=\"0 0 34 29\" xmlns=\"http:\/\/www.w3.org\/2000\/svg\"><g fill=\"#18217e\" opacity=\".5\"><path d=\"m10.6 13.1c-.8-.2-1.6-.4-2.4-.4-1.2 0-2.2.3-3 .7.8-2.9 2.6-8 6.2-8.5.3-.1.6-.4.6-.7l.8-3c.1-.3 0-.5-.1-.7s-.4-.4-.6-.4c-.2-.1-.5-.1-.8-.1-4.4 0-8.7 4.8-10.5 11.6-1.1 4-1.4 10.1 1.3 13.9 1.5 2.1 3.6 3.3 6.4 3.4 3.4 0 6.5-2.4 7.4-5.9.6-2.1.3-4.2-.7-6.1s-2.7-3.2-4.6-3.8z\"\/><path d=\"m33 16.9c-1-1.9-2.6-3.2-4.6-3.8-.8-.2-1.6-.4-2.4-.4-1.2 0-2.2.3-3 .7.8-2.9 2.6-8 6.2-8.5.3-.1.6-.3.7-.7l.8-3c.1-.3 0-.5-.1-.7s-.4-.4-.6-.4c-.3-.1-.6-.1-.8-.1-4.4 0-8.7 4.8-10.5 11.6-1.1 4-1.4 10.1 1.3 13.9 1.5 2.1 3.6 3.3 6.4 3.4 3.4 0 6.5-2.4 7.4-5.9.5-2.1.2-4.2-.8-6.1z\"\/><\/g><\/svg><div><div class=\"entry-content\">\u201cJust think: when you search for \u2018dogs\u2019, you probably don\u2019t want a page with the word \u2018dogs\u2019 on it hundreds of times. With that in mind, algorithms assess if a page contains other relevant content beyond the keyword \u2018dogs\u2019 \u2013 such as pictures of dogs, videos or even a list of breeds.\u201d<\/div><cite class=\"opacity-0-5\">Google<\/cite><\/div><\/blockquote>\n<p>Google is able to see that a list of dog breeds is semantically related to the core keyword \u201cdogs\u201d.<\/p>\n<p>Say we had two pages, both of which contain the same number of mentions of \u201cfootball\u201d, but, one is about sports (Page A) in general, and the other is about football (Page B).<\/p>\n<p>\ud83e\udd14 <em>Which one should rank higher?<\/em><\/p>\n<p>Looking at the surrounding text helps determine which page should rank higher than the other.<\/p>\n<p>Therefore, Page B would be ranked higher by Google because it is able to use the compound keywords (related keywords) to determine the article\u2019s topical relevance to the core search term \u201cfootball\u201d.<\/p>\n<h3>The SUSO Method: Finding Compound Keywords<\/h3>\n<p>If you\u2019re writing about a topic that you\u2019re already familiar and knowledgeable about, you\u2019ll naturally include compound keywords within your copy. After all, that\u2019s how it should be!<\/p>\n<p>For example, when writing an article about the best Italian restaurants in London you would likely mention words and phrases like \u201cpasta\u201d, \u201cpizza\u201d and \u201cspaghetti\u201d.<\/p>\n<p>That being said, for topics that may be more complex or unfamiliar, important compound keywords may be missed out.<\/p>\n<p>So, let\u2019s take a look at how you can (quickly and easily) find additional terms to include within your content.<\/p>\n<h4>Look At Google Autocomplete<\/h4>\n<p>One of the quickest ways to find compound keywords is using a simple Google search. <a href=\"https:\/\/susodigital.com\/textbook\/module\/how-google-works\/the-search-results-page\">Google\u2019s autocomplete feature<\/a> (which we\u2019ve already covered previously), can give you an insight into what might be worth mentioning in your content.<\/p>\n<p>For example, if we search \u201chow to use apple pay\u201d, we can see that Google presents several suggestions on similar related keywords. Importantly, this also shows you what user\u2019s are likely looking for too.<\/p>\n<img loading=\"lazy\" class=\"aligncenter size-full wp-image-964\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-How-to-use-autocomplete-in-Google.png\" alt=\"How to use autocomplete in Google\" width=\"884\" height=\"794\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-How-to-use-autocomplete-in-Google.png 884w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-How-to-use-autocomplete-in-Google-45x40.png 45w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-How-to-use-autocomplete-in-Google-89x80.png 89w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-How-to-use-autocomplete-in-Google-33x30.png 33w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-How-to-use-autocomplete-in-Google-67x60.png 67w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-How-to-use-autocomplete-in-Google-27x24.png 27w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-How-to-use-autocomplete-in-Google-53x48.png 53w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-How-to-use-autocomplete-in-Google-20x18.png 20w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-How-to-use-autocomplete-in-Google-40x36.png 40w\" sizes=\"(max-width: 884px) 100vw, 884px\" \/>\n<p>The above recommendations imply that you should write about how to use Apple Pay on specific Apple devices.<\/p>\n<h4>Look At Google Related Searches<\/h4>\n<p>Apart from autocomplete, Google also suggests related queries at the bottom of the search results page.<\/p>\n<p>If we were to write an article about How To Make Slime, we can see that Google displays several suggestions that it believes are already related to this original query.<\/p>\n<img loading=\"lazy\" class=\"aligncenter size-full wp-image-965\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Google-related-queries.png\" alt=\"Google related queries\" width=\"785\" height=\"359\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Google-related-queries.png 785w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Google-related-queries-87x40.png 87w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Google-related-queries-175x80.png 175w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Google-related-queries-66x30.png 66w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Google-related-queries-131x60.png 131w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Google-related-queries-52x24.png 52w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Google-related-queries-105x48.png 105w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Google-related-queries-39x18.png 39w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Google-related-queries-79x36.png 79w\" sizes=\"(max-width: 785px) 100vw, 785px\" \/>\n<p>So if you\u2019re going to write about slime, make sure to include terms like \u201ctoothpaste\u201d, \u201cborax\u201d, \u201cglue\u201d etc.<\/p>\n<h4>Reverse-Engineer the Knowledge Graph<\/h4>\n<p>Google\u2019s Knowledge Graph is a treasure trove of finding related information for entities &#8211; this includes data about people, places, things or even concepts. Importantly, on top of the core pieces of information about these entities, Google also stores the relationships between them.<\/p>\n<p>Let\u2019s take a look at an example.<\/p>\n<img loading=\"lazy\" class=\"aligncenter size-full wp-image-966\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Knowledge-graph-example-of-Donald-Glover.png\" alt=\"Knowledge graph example of Donald Glover\" width=\"327\" height=\"887\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Knowledge-graph-example-of-Donald-Glover.png 327w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Knowledge-graph-example-of-Donald-Glover-15x40.png 15w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Knowledge-graph-example-of-Donald-Glover-29x80.png 29w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Knowledge-graph-example-of-Donald-Glover-11x30.png 11w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Knowledge-graph-example-of-Donald-Glover-22x60.png 22w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Knowledge-graph-example-of-Donald-Glover-9x24.png 9w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Knowledge-graph-example-of-Donald-Glover-18x48.png 18w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Knowledge-graph-example-of-Donald-Glover-7x18.png 7w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Knowledge-graph-example-of-Donald-Glover-13x36.png 13w\" sizes=\"(max-width: 327px) 100vw, 327px\" \/>\n<p>In the Knowledge Graph for Donald Glover, we can see that Google provides a list of entities that people also search for. However, you can also use the list of Movies and Tv shows as pointers as to what terms\/topics should appear too.<\/p>\n<h4>Use An \u201cLSI Keyword\u201d Generator<\/h4>\n<p>There are lots of tools out there that generate \u201cLSI Keywords\u201d, but of course, we now know that LSI keywords don\u2019t actually exist and that these generators probably don\u2019t have anything to do with Latent Semantic Indexing. However, regardless of what label we give them, they do offer quick and easy insights into what kinds of terms you should be using within your content.<\/p>\n<p>A popular tool is <a href=\"https:\/\/lsigraph.com\/\" target=\"_blank\" rel=\"noopener\">LSIGraph<\/a>, which generates \u201cthe most profitable semantically related keywords\u201d. All you have to do is type in the keyword you want to find compound terms for and the tool does the rest.<\/p>\n<img loading=\"lazy\" class=\"aligncenter size-full wp-image-967\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-LSIgraph-example.png\" alt=\"LSIgraph example\" width=\"957\" height=\"799\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-LSIgraph-example.png 957w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-LSIgraph-example-48x40.png 48w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-LSIgraph-example-96x80.png 96w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-LSIgraph-example-36x30.png 36w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-LSIgraph-example-72x60.png 72w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-LSIgraph-example-29x24.png 29w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-LSIgraph-example-57x48.png 57w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-LSIgraph-example-22x18.png 22w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-LSIgraph-example-43x36.png 43w\" sizes=\"(max-width: 957px) 100vw, 957px\" \/>\n<p>For example, if we plug in the keyword \u201cdonald glover\u201d, we can see that it provides a long list of possible related terms and phrases that could be used.<\/p>\n<h4>Reverse-Engineer Your Competitors<\/h4>\n<p>Looking at the keywords that the top competing pages for the core term you want to target are ranking for is a great way of finding hidden gems that you may otherwise have overlooked. For this, we would recommend using <a href=\"https:\/\/ahrefs.com\/keywords-explorer\" target=\"_blank\" rel=\"noopener\">Ahrefs\u2019 Keyword Explorer tool<\/a> to find compound terms.<\/p>\n<img loading=\"lazy\" class=\"aligncenter size-full wp-image-968\" src=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Ahrefs-Keyword-Explorer-tool.png\" alt=\"Ahrefs Keyword Explorer tool\" width=\"1335\" height=\"870\" srcset=\"https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Ahrefs-Keyword-Explorer-tool.png 1335w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Ahrefs-Keyword-Explorer-tool-61x40.png 61w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Ahrefs-Keyword-Explorer-tool-123x80.png 123w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Ahrefs-Keyword-Explorer-tool-46x30.png 46w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Ahrefs-Keyword-Explorer-tool-92x60.png 92w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Ahrefs-Keyword-Explorer-tool-37x24.png 37w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Ahrefs-Keyword-Explorer-tool-74x48.png 74w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Ahrefs-Keyword-Explorer-tool-28x18.png 28w, https:\/\/susodigital.com\/textbook\/wp-content\/uploads\/2020\/07\/M5-Ahrefs-Keyword-Explorer-tool-55x36.png 55w\" sizes=\"(max-width: 1335px) 100vw, 1335px\" \/>\n<p>The \u201cAlso rank for\u201d feature is perfect for this; see the example above for \u201chow to make slime\u201d.<\/p>\n<p>If you don\u2019t have Ahrefs, you can still reverse-engineer the top ranking pages for the keywords you want to rank for by manually looking at the pages themselves for topics or terms that you perhaps have overlooked.<\/p>\n<h3>The SUSO Method: Using Compound Keywords<\/h3>\n<p>Once you\u2019ve got a long list of compound keywords and related terms, you need to use them effectively in your content.<\/p>\n<p>It\u2019s important to ensure that the keywords that you have collected <a href=\"https:\/\/susodigital.com\/textbook\/module\/semantic-search\/intent\">satisfy the user intent<\/a> and answer the core questions that the user might have about that particular topic or search query.<\/p>\n<p>Remember, there are three main types of intent based keywords:<\/p>\n<ol>\n<li>Informational &#8211; keywords that aim to inform the user on a broader scale i.e. \u201cwhat is the movie Parasite about\u201d<\/li>\n<li>Navigational &#8211; keywords that are more specific i.e. \u201cwho directed Parasite\u201d<\/li>\n<li>Transactional &#8211; keywords that relate to making a purchase i.e. \u201cParasite dvd\u201d<\/li>\n<\/ol>\n<p>Once you\u2019ve categorised the keywords based on their intent, you can then align these with your existing content and see where they fit in contextually. In some cases, you may need to add an entirely new section to help target a specific subset of compound keywords.<\/p>\n<p>For instance, if you want to add some content about topics like \u201chow to make slime\u201d you may have different subheadings for different ways to make slime i.e. \u201cwithout borax\u201d, or \u201cwith glue\u201d etc.<\/p>\n<h2>Verdict<\/h2>\n<p>Latent Semantic Indexing and LSI Keywords aren\u2019t exactly what they appear to be on the surface. Google almost definitely does not use Latent Semantic Indexing and have written off LSI keywords, but ultimately, what we can confirm, is that semantically related words (compound keywords), are important, and Google is definitely looking at these to improve their understanding of language and content.<\/p>\n<p>For this reason alone, including compound keywords within your content is beneficial for your SEO.<\/p>\n<p>You just have to ensure that these related terms are used sparingly and within the right context to avoid keyword stuffing.<\/p>\n"},"_links":{"self":[{"href":"https:\/\/susodigital.com\/textbook\/wp-json\/wp\/v2\/modules\/951"}],"collection":[{"href":"https:\/\/susodigital.com\/textbook\/wp-json\/wp\/v2\/modules"}],"about":[{"href":"https:\/\/susodigital.com\/textbook\/wp-json\/wp\/v2\/types\/module"}],"version-history":[{"count":4,"href":"https:\/\/susodigital.com\/textbook\/wp-json\/wp\/v2\/modules\/951\/revisions"}],"predecessor-version":[{"id":2185,"href":"https:\/\/susodigital.com\/textbook\/wp-json\/wp\/v2\/modules\/951\/revisions\/2185"}],"up":[{"embeddable":true,"href":"https:\/\/susodigital.com\/textbook\/wp-json\/wp\/v2\/modules\/393"}],"wp:attachment":[{"href":"https:\/\/susodigital.com\/textbook\/wp-json\/wp\/v2\/media?parent=951"}],"curies":[{"name":"wp","href":"https:\/\/api.w.org\/{rel}","templated":true}]}}